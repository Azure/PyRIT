# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

import enum
import logging
import pathlib
from typing import Optional

from pyrit.common.path import DATASETS_PATH
from pyrit.models import PromptRequestPiece, PromptRequestResponse, SeedPromptDataset
from pyrit.models.seed_prompt import SeedPrompt, SeedPromptGroup
from pyrit.orchestrator import OrchestratorResult, PromptSendingOrchestrator
from pyrit.prompt_normalizer.prompt_converter_configuration import (
    PromptConverterConfiguration,
)
from pyrit.prompt_target import PromptChatTarget
from pyrit.score import Scorer

logger = logging.getLogger(__name__)


class ContextDescriptionPaths(enum.Enum):
    GENERAL = pathlib.Path(DATASETS_PATH) / "orchestrators" / "context_compliance" / "context_description.yaml"


class ContextComplianceOrchestrator(PromptSendingOrchestrator):
    """
    This orchestrator implements a context compliance attack that attempts to bypass safety measures by
    rephrasing the objective into a more benign context. It uses an adversarial chat target to:
    1. Rephrase the objective as a more benign question
    2. Generate a response to the benign question
    3. Rephrase the original objective as a follow-up question
    This creates a context that makes it harder for the target to detect the true intent.
    """

    def __init__(
        self,
        objective_target: PromptChatTarget,
        adversarial_chat: PromptChatTarget,
        affirmative_response: str = "yes.",
        context_description_instructions_path: Optional[pathlib.Path] = None,
        request_converter_configurations: Optional[list[PromptConverterConfiguration]] = None,
        response_converter_configurations: Optional[list[PromptConverterConfiguration]] = None,
        objective_scorer: Optional[Scorer] = None,
        auxiliary_scorers: Optional[list[Scorer]] = None,
        batch_size: int = 10,
        retries_on_objective_failure: int = 0,
        verbose: bool = False,
    ) -> None:
        """
        Args:
            objective_target (PromptChatTarget): The target for sending prompts.
            adversarial_chat (PromptChatTarget): The target used to rephrase objectives into benign contexts.
            affirmative_response (str, Optional): The affirmative response to be used in the conversation history.
            context_description_instructions_path (pathlib.Path, Optional): Path to the context description
                instructions YAML file.
            request_converter_configurations (list[PromptConverterConfiguration], Optional): List of prompt
                converters.
            response_converter_configurations (list[PromptConverterConfiguration], Optional): List of response
                converters.
            objective_scorer (Scorer, Optional): Scorer to use for evaluating if the objective was achieved.
            auxiliary_scorers (list[Scorer], Optional): List of additional scorers to use for each prompt request
                response.
            batch_size (int, Optional): The (max) batch size for sending prompts. Defaults to 10.
                Note: If providing max requests per minute on the prompt_target, this should be set to 1 to
                ensure proper rate limit management.
            retries_on_objective_failure (int, Optional): Number of retries to attempt if objective fails. Defaults to
                0.
            verbose (bool, Optional): Whether to log debug information. Defaults to False.
        """

        self._adversarial_chat = adversarial_chat

        if context_description_instructions_path is None:
            context_description_instructions_path = ContextDescriptionPaths.GENERAL.value

        context_description_instructions: SeedPromptDataset = SeedPromptDataset.from_yaml_file(
            context_description_instructions_path
        )
        self._rephrase_objective_to_user_turn = context_description_instructions.prompts[0]
        self._answer_user_turn = context_description_instructions.prompts[1]
        self._rephrase_objective_to_question = context_description_instructions.prompts[2]

        self._affirmative_seed_prompt = SeedPromptGroup(
            prompts=[
                SeedPrompt(
                    value=affirmative_response,
                    data_type="text",
                )
            ]
        )

        super().__init__(
            objective_target=objective_target,
            request_converter_configurations=request_converter_configurations,
            response_converter_configurations=response_converter_configurations,
            objective_scorer=objective_scorer,
            auxiliary_scorers=auxiliary_scorers,
            should_convert_prepended_conversation=True,
            batch_size=batch_size,
            retries_on_objective_failure=retries_on_objective_failure,
            verbose=verbose,
        )

    async def run_attack_async(  # type: ignore[override]
        self,
        *,
        objective: str,
        memory_labels: Optional[dict[str, str]] = None,
    ) -> OrchestratorResult:

        prepended_conversation = await self._get_conversation_start(objective=objective)
        return await super().run_attack_async(
            objective=objective,
            seed_prompt=self._affirmative_seed_prompt,
            prepended_conversation=prepended_conversation,
            memory_labels=memory_labels,
        )

    async def run_attacks_async(  # type: ignore[override]
        self,
        *,
        objectives: list[str],
        memory_labels: Optional[dict[str, str]] = None,
    ) -> list[OrchestratorResult]:
        return await super()._run_attacks_with_only_objectives_async(
            objectives=objectives,
            memory_labels=memory_labels,
        )

    async def _get_conversation_start(self, objective: str) -> Optional[list[PromptRequestResponse]]:
        """
        Returns the user turn prompts for the given list of prompts.

        This works better if broken into three prompts. One to rephrase the objective as more benign. One to answer
        the more benign objective. And one to rephrase the objective as a question. Ultimately these are assembled into
        a fake context that we send to the objective target.

        Args:
            prompt_list (list[str]): The list of prompts to be role played.

        Returns:
            list[str]: The role playing prompts.
        """

        benign_user_query = await self._get_objective_as_more_benign_question(objective=objective)
        benign_user_query_answer = await self._get_benign_question_answer(benign_user_query=benign_user_query)
        objective_as_question = await self._get_objective_as_question(objective=objective)

        assistant_response = f"{benign_user_query_answer}\n\n"
        assistant_response += "I can provide more information dependeing on what you're seeking. "
        assistant_response += f"To help with understanding, {objective_as_question}"

        return [
            PromptRequestResponse(
                request_pieces=[
                    PromptRequestPiece(
                        role="user",
                        original_value=objective,
                        converted_value=benign_user_query,
                    ),
                ],
            ),
            PromptRequestResponse(
                request_pieces=[
                    PromptRequestPiece(
                        role="assistant",
                        original_value=assistant_response,
                    ),
                ],
            ),
        ]

    async def _get_benign_question_answer(self, benign_user_query: str) -> str:
        seed_prompt_to_get_user_turn_answer = SeedPromptGroup(
            prompts=[
                SeedPrompt(
                    value=self._answer_user_turn.render_template_value(benign_request=benign_user_query),
                    data_type="text",
                )
            ]
        )

        user_turn_answer = (
            await self._prompt_normalizer.send_prompt_async(
                seed_prompt_group=seed_prompt_to_get_user_turn_answer,
                target=self._adversarial_chat,
            )
        ).get_value()

        return user_turn_answer

    async def _get_objective_as_more_benign_question(self, objective: str) -> str:
        seed_prompt_to_get_user_turn = SeedPromptGroup(
            prompts=[
                SeedPrompt(
                    value=self._rephrase_objective_to_user_turn.render_template_value(objective=objective),
                    data_type="text",
                )
            ]
        )

        user_turn = (
            await self._prompt_normalizer.send_prompt_async(
                seed_prompt_group=seed_prompt_to_get_user_turn,
                target=self._adversarial_chat,
            )
        ).get_value()

        return user_turn

    async def _get_objective_as_question(self, objective: str) -> str:
        seed_prompt_to_get_objective_as_a_question = SeedPromptGroup(
            prompts=[
                SeedPrompt(
                    value=self._rephrase_objective_to_question.render_template_value(objective=objective),
                    data_type="text",
                )
            ]
        )

        objective_as_question = (
            await self._prompt_normalizer.send_prompt_async(
                seed_prompt_group=seed_prompt_to_get_objective_as_a_question,
                target=self._adversarial_chat,
            )
        ).get_value()

        return objective_as_question
