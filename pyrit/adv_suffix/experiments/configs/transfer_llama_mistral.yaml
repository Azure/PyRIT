transfer: True
logfile: ""
progressive_goals: False
stop_on_success: False
tokenizer_paths: ["meta-llama/Llama-2-7b-chat-hf", "mistralai/Mistral-7B-Instruct-v0.1"]
tokenizer_kwargs: [{"use_fast": False}, {"use_fast": False}]
model_paths: ["meta-llama/Llama-2-7b-chat-hf", "mistralai/Mistral-7B-Instruct-v0.1"]
model_kwargs: [{"low_cpu_mem_usage": True, "use_cache": False}, {"low_cpu_mem_usage": True, "use_cache": False}]
conversation_templates: ["llama-2", "mistral"]
devices: ["cuda:0", "cuda:1"]