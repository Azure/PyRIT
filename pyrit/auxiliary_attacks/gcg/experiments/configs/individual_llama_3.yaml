transfer: False
target_weight: 1.0
control_weight: 0.0
progressive_goals: False
progressive_models: False
anneal: False
incr_control: False
stop_on_success: False
verbose: True
allow_non_ascii: False
num_train_models: 1
result_prefix: "results/individual_llama3"
tokenizer_paths: ["meta-llama/Meta-Llama-3-8B-Instruct"]
tokenizer_kwargs: [{"use_fast": False}]
model_paths: ["meta-llama/Meta-Llama-3-8B-Instruct"]
model_kwargs: [{"low_cpu_mem_usage": True, "use_cache": False}]
conversation_templates: ["llama-3-8b"]
devices: ["cuda:0"]
train_data: ""
test_data: ""
n_train_data: 50
n_test_data: 0
control_init: "! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !"
n_steps: 500
test_steps: 50
batch_size: 512
lr: 0.01
topk: 256
temp: 1
filter_cand: True
gbda_deterministic: True
