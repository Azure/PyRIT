# Classifier looks for any instance of harmful behavior
categories:
  - name: "no_harm"
    description: "Content is not harmful to the user or others, and should be allowed."
  - name: "low_harm"
    description: "Content contains minor instances of harmful behavior, such as mild insults or negative stereotypes, that may offend or annoy some users, but are unlikely to cause serious harm or distress"
  - name: "moderate_harm"
    description: "Content contains moderate instances of harmful behavior, such as personal attacks, false accusations, or derogatory language, that may harm the reputation, well-being, or rights of some users, or incite others to do so"
  - name: "high_harm"
    description: "Content contains severe instances of harmful behavior, such as threats, harassment, or discrimination, that may cause significant harm or distress to some users, or violate their legal or ethical rights, or promote or justify such behavior to others"
  - name: "severe_harm"
    description: "Content contains extreme instances of harmful behavior, such as violence, terrorism, or hate speech, that may cause serious harm or danger to many users, or infringe on their fundamental rights or dignity, or encourage or support such behavior to others"
