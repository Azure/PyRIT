{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Registering Hugging Face Models into Azure ML\n",
    "\n",
    "This notebook demonstrates the process of importing models from the [Hugging Face hub](https://huggingface.co/models) and registering them into Azure Machine Learning (AML) for further use in various machine learning tasks.\n",
    "\n",
    "### Why Hugging Face Models in PyRIT?\n",
    "The primary goal of PyRIT is to assess the robustness of LLM endpoints against different harm categories such as fabrication/ungrounded content (e.g., hallucination), misuse (e.g., bias), and prohibited content (e.g., harassment). Hugging Face serves as a comprehensive repository of LLMs, capable of generating a diverse and complex prompts when given appropriate system prompt. Models such as:\n",
    "- [\"TheBloke/llama2_70b_chat_uncensored-GGML\"](https://huggingface.co/TheBloke/llama2_70b_chat_uncensored-GGML)\n",
    "- [\"cognitivecomputations/Wizard-Vicuna-30B-Uncensored\"](https://huggingface.co/cognitivecomputations/Wizard-Vicuna-30B-Uncensored)\n",
    "- [\"lmsys/vicuna-13b-v1.1\"](https://huggingface.co/lmsys/vicuna-13b-v1.1)\n",
    "\n",
    "are particularly useful for generating prompts or scenarios without content moderation. These can be configured as part of a `RedTeamingBot` in PyRIT to create challenging and uncensored prompts/scenarios. These prompts are then submitted to the target chat bot, helping assess its ability to handle potentially unsafe, unexpected, or adversarial inputs.\n",
    "\n",
    "### Important Note on Deploying Quantized Models\n",
    "When deploying quantized models, especially those suffixed with GGML, FP16, or GPTQ, it's crucial to have GPU support. These models are optimized for performance but require the computational capabilities of GPUs to run. Ensure your deployment environment is equipped with the necessary GPU resources to handle these models.\n",
    "\n",
    "### Supported Tasks\n",
    "The import process supports a variety of tasks, including but not limited to:\n",
    "- Text classification\n",
    "- Text generation\n",
    "- Question answering\n",
    "- Summarization\n",
    "\n",
    "### Import Process\n",
    "The process involves downloading models from the Hugging Face hub, converting them to MLflow format for compatibility with Azure ML, and then registering them for easy access and deployment.\n",
    "\n",
    "### Prerequisites\n",
    "- An Azure account with an active subscription. [Create one for free](https://azure.microsoft.com/free/).\n",
    "- An Azure ML workspace set up. [Learn how to set up a workspace](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace).\n",
    "- Install the Azure ML client library for Python with pip.\n",
    "  ```bash\n",
    "     pip install azure-ai-ml\n",
    "     pip install azure-identity\n",
    "  ```\n",
    "- Execute the `az login` command to sign in to your Azure subscription. For detailed instructions, refer to the \"Authenticate with Azure Subscription\" section in the notebook provided [here](../setup/azure_openai_setup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "Before we start, we need to connect to our Azure ML workspace. The workspace is the top-level resource for Azure ML, providing a centralized place to work with all the artifacts you create.\n",
    "\n",
    "### Steps:\n",
    "1. **Import Required Libraries**: We'll start by importing the necessary libraries from the Azure ML SDK.\n",
    "2. **Set Up Credentials**: We'll use `DefaultAzureCredential` or `InteractiveBrowserCredential` for authentication.\n",
    "3. **Access Workspace and Registry**: We'll obtain handles to our AML workspace and the model registry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Required Libraries\n",
    "\n",
    "Import the Azure ML SDK components required for workspace connection and model management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Azure ML operations and authentication\n",
    "from azure.ai.ml import MLClient, UserIdentityConfiguration\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.core.exceptions import ResourceNotFoundError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Environment Variables\n",
    "\n",
    "Load necessary environment variables from an `.env` file.\n",
    "\n",
    "To execute the following job on an AML compute cluster, set `AML_COMPUTE_TYPE` to `amlcompute` and specify `AML_INSTANCE_SIZE` as `STANDARD_D4_V2` (or other as you see fit). When utilizing the model import component, `AML_REGISTRY_NAME` should be set to `azureml`, and `AML_MODEL_IMPORT_VERSION` can be either `latest` or a specific version like `0.0.22`. For Hugging Face models, the `TASK_NAME` might be `text-generation`. For default values and further guidance, please see the `.env_example` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the dotenv package if you haven't already\n",
    "# !pip install python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "subscription_id = os.getenv('AZURE_SUBSCRIPTION_ID')\n",
    "resource_group = os.getenv('AZURE_RESOURCE_GROUP')\n",
    "workspace_name = os.getenv('AML_WORKSPACE_NAME')\n",
    "registry_name = os.getenv('AML_REGISTRY_NAME')\n",
    "aml_import_model_version = os.getenv('AML_MODEL_IMPORT_VERSION') # values could be 'latest' or any version\n",
    "\n",
    "# Model and Compute Configuration\n",
    "model_id = os.getenv('HF_MODEL_ID')\n",
    "task_name = os.getenv('TASK_NAME')\n",
    "aml_compute_type = os.getenv(\"AML_COMPUTE_TYPE\")\n",
    "instance_size = os.getenv('AML_INSTANCE_SIZE')\n",
    "compute_name = os.getenv('AML_COMPUTE_NAME')\n",
    "experiment_name = f\"Import Model Pipeline Hugging Face model {model_id}\"\n",
    "min_instances = os.getenv(\"AML_MIN_INSTANCES\")\n",
    "max_instances = os.getenv(\"AML_MAX_INSTANCES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Configure Credentials\n",
    "\n",
    "Set up the `DefaultAzureCredential` for seamless authentication with Azure services. This method should handle most authentication scenarios. If you encounter issues, refer to the [Azure Identity documentation](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python) for alternative credentials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Azure credentials, preferring DefaultAzureCredential and falling back to InteractiveBrowserCredential if necessary\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Verify if the default credential can fetch a token successfully\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    print(\"DefaultAzureCredential failed, falling back to InteractiveBrowserCredential:\", ex)\n",
    "    credential = InteractiveBrowserCredential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Access Azure ML Workspace and Registry\n",
    "\n",
    "Using the Azure ML SDK, we'll connect to our workspace. This requires having a configuration file or setting up the workspace parameters directly in the code. Ensure your workspace is configured with a compute instance or cluster for running the jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLClient for AML workspace and registry access\n",
    "try:\n",
    "    # Attempt to create MLClient using configuration file\n",
    "    ml_client_ws = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    ml_client_ws = MLClient(\n",
    "        credential,\n",
    "        subscription_id=subscription_id,\n",
    "        resource_group_name=resource_group,\n",
    "        workspace_name=workspace_name,\n",
    "    )\n",
    "# Initialize MLClient for AML model registry access\n",
    "ml_client_registry = MLClient(credential, registry_name=registry_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Compute Target Setup\n",
    "\n",
    "For model operations, we need a compute target. Here, we'll either attach an existing AmlCompute or create a new one. Note that creating a new AmlCompute can take approximately 5 minutes.\n",
    "\n",
    "- **Existing AmlCompute**: If an AmlCompute with the specified name exists, we'll use it.\n",
    "- **New AmlCompute**: If it doesn't exist, we'll create a new one. Be aware of the [resource limits](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-quotas) in Azure ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup or retrieve the compute target for model training\n",
    "try:\n",
    "    # Check if the compute target already exists\n",
    "    _ = ml_client_ws.compute.get(compute_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "except ResourceNotFoundError:\n",
    "    # If not found, create a new compute target\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute(\n",
    "        name=compute_name,\n",
    "        type=aml_compute_type,\n",
    "        size=instance_size,\n",
    "        min_instances=min_instances,\n",
    "        max_instances=max_instances,\n",
    "    )\n",
    "    ml_client_ws.begin_create_or_update(compute_config).result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an AML Pipeline for Hugging Face Models\n",
    "\n",
    "In this section, we'll set up a pipeline to import and register Hugging Face models into Azure ML.\n",
    "\n",
    "### Steps:\n",
    "1. **Load Pipeline Component**: We'll load the necessary pipeline component from the Azure ML registry.\n",
    "2. **Define Pipeline Parameters**: We'll specify parameters such as the Hugging Face model ID and compute target.\n",
    "3. **Create Pipeline**: Using the loaded component and parameters, we'll define the pipeline.\n",
    "4. **Execute Pipeline**: We'll submit the pipeline job to Azure ML and monitor its progress.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Pipeline Component\n",
    "\n",
    "Load the `import_model` pipeline component from the Azure ML registry. This component is responsible for downloading the Hugging Face model, converting it to MLflow format, and registering it in Azure ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_model = ml_client_registry.components.get(name=\"import_model\", version=aml_import_model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Hugging Face model exists in the Azure ML model registry\n",
    "\n",
    "huggingface_model_exists_in_aml_registry = False\n",
    "try:\n",
    "    registered_model_id = model_id.replace(\"/\", \"-\")  # Replace '/' with '-' for AML registry compatibility\n",
    "    models = ml_client_registry.models.list(name=registered_model_id)\n",
    "    if models:\n",
    "        max_version = max(models, key=lambda x: int(x.version)).version\n",
    "        model_version = str(int(max_version))\n",
    "        print(f\"Model already exists in Azure ML model catalog with name {registered_model_id} and version {model_version}\")\n",
    "        huggingface_model_exists_in_aml_registry = True\n",
    "except Exception as e:\n",
    "    print(f\"Model {registered_model_id} not found in registry. Please continue importing the model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create and Configure the Pipeline\n",
    "\n",
    "Define the pipeline using the `import_model` component and the specified parameters. We'll also set up the User Identity Configuration for the pipeline, allowing individual components to access identity credentials if required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a AML pipeline for importing models into Azure ML\n",
    "@pipeline\n",
    "def model_import_pipeline(model_id, compute, task_name, instance_type):\n",
    "    \"\"\"\n",
    "    Pipeline to import a model into Azure ML.\n",
    "\n",
    "    Parameters:\n",
    "    - model_id: The ID of the model to import.\n",
    "    - compute: The compute resource to use for the import job.\n",
    "    - task_name: The task associated with the model.\n",
    "    - instance_type: The type of instance to use for the job.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing model registration details.\n",
    "    \"\"\"\n",
    "    import_model_job = import_model(\n",
    "        model_id=model_id, compute=compute, task_name=task_name, instance_type=instance_type\n",
    "    )\n",
    "    import_model_job.settings.continue_on_step_failure = False  # Do not continue on failure\n",
    "\n",
    "    return {\"model_registration_details\": import_model_job.outputs.model_registration_details}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the pipeline object with necessary parameters and identity\n",
    "pipeline_object = model_import_pipeline(\n",
    "    model_id=model_id,\n",
    "    compute=compute_name,\n",
    "    task_name=task_name,\n",
    "    instance_type=instance_size\n",
    ")\n",
    "pipeline_object.identity = UserIdentityConfiguration()\n",
    "pipeline_object.settings.force_rerun = True\n",
    "pipeline_object.settings.default_compute = compute_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if the pipeline needs to be scheduled for model import\n",
    "schedule_huggingface_model_import = (\n",
    "    not huggingface_model_exists_in_aml_registry and model_id not in [None, \"None\"] and len(model_id) > 1\n",
    ")\n",
    "print(f\"Need to schedule run for importing {model_id}: {schedule_huggingface_model_import}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Submit the Pipeline Job\n",
    "\n",
    "Submit the pipeline job to Azure ML for execution. The job will import the specified Hugging Face model and register it in Azure ML. We'll monitor the job's progress and output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit and monitor the pipeline job if model import is scheduled\n",
    "if schedule_huggingface_model_import:\n",
    "    huggingface_pipeline_job = ml_client_ws.jobs.create_or_update(\n",
    "        pipeline_object, experiment_name=experiment_name\n",
    "    )\n",
    "    ml_client_ws.jobs.stream(huggingface_pipeline_job.name)  # Stream logs to monitor the job\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
