# This is an example of the .env file. Copy to ~/.pyrit/.env and fill in your endpoint configurations.
# Note that if you are using Entra authentication for certain Azure resources (use_entra_auth = True in PyRIT),
# keys for those resources are not needed.


###################################
# OPENAI TARGET SECRETS
#
# The below models work with OpenAIChatTarget - either pass via environment variables
# or copy to OPENAI_CHAT_ENDPOINT
###################################

PLATFORM_OPENAI_CHAT_ENDPOINT="https://api.openai.com/v1"
PLATFORM_OPENAI_CHAT_API_KEY="sk-xxxxx"
PLATFORM_OPENAI_CHAT_GPT4O_MODEL="gpt-4o"

# Note: For Azure OpenAI endpoints, use the new format with /openai/v1 and specify the model separately
# Example: https://xxxx.openai.azure.com/openai/v1
AZURE_OPENAI_GPT4O_ENDPOINT="https://xxxx.openai.azure.com/openai/v1"
AZURE_OPENAI_GPT4O_KEY="xxxxx"
AZURE_OPENAI_GPT4O_MODEL="deployment-name"
# Since Azure deployment name may be custom and differ from the actual underlying model,
# you can specify the underlying model for identifier purposes. If not specified,
# identifiers will default to the value of the standard MODEL environment variable.
AZURE_OPENAI_GPT4O_UNDERLYING_MODEL="gpt-4o"

AZURE_OPENAI_INTEGRATION_TEST_ENDPOINT="https://xxxxx.openai.azure.com/openai/v1"
AZURE_OPENAI_INTEGRATION_TEST_KEY="xxxxx"
AZURE_OPENAI_INTEGRATION_TEST_MODEL="deployment-name"
AZURE_OPENAI_INTEGRATION_TEST_UNDERLYING_MODEL=""

AZURE_OPENAI_GPT3_5_CHAT_ENDPOINT="https://xxxxx.openai.azure.com/openai/v1"
AZURE_OPENAI_GPT3_5_CHAT_KEY="xxxxx"
AZURE_OPENAI_GPT3_5_CHAT_MODEL="deployment-name"
AZURE_OPENAI_GPT3_5_CHAT_UNDERLYING_MODEL=""

AZURE_OPENAI_GPT4_CHAT_ENDPOINT="https://xxxxx.openai.azure.com/openai/v1"
AZURE_OPENAI_GPT4_CHAT_KEY="xxxxx"
AZURE_OPENAI_GPT4_CHAT_MODEL="deployment-name"
AZURE_OPENAI_GPT4_CHAT_UNDERLYING_MODEL=""

# Endpoints that host models with fewer safety mechanisms (e.g. via adversarial fine tuning
# or content filters turned off) can be defined below and used in adversarial attack testing scenarios.
AZURE_OPENAI_GPT4O_UNSAFE_CHAT_ENDPOINT="https://xxxxx.openai.azure.com/openai/v1"
AZURE_OPENAI_GPT4O_UNSAFE_CHAT_KEY="xxxxx"
AZURE_OPENAI_GPT4O_UNSAFE_CHAT_MODEL="deployment-name"
AZURE_OPENAI_GPT4O_UNSAFE_CHAT_UNDERLYING_MODEL=""

AZURE_OPENAI_GPT4O_UNSAFE_CHAT_ENDPOINT2="https://xxxxx.openai.azure.com/openai/v1"
AZURE_OPENAI_GPT4O_UNSAFE_CHAT_KEY2="xxxxx"
AZURE_OPENAI_GPT4O_UNSAFE_CHAT_MODEL2="deployment-name"
AZURE_OPENAI_GPT4O_UNSAFE_CHAT_UNDERLYING_MODEL2=""

AZURE_FOUNDRY_DEEPSEEK_ENDPOINT="https://xxxxx.eastus2.models.ai.azure.com"
AZURE_FOUNDRY_DEEPSEEK_KEY="xxxxx"
AZURE_FOUNDRY_DEEPSEEK_MODEL=""

AZURE_FOUNDRY_PHI4_ENDPOINT="https://xxxxx.models.ai.azure.com"
AZURE_CHAT_PHI4_KEY="xxxxx"
AZURE_FOUNDRY_PHI4_MODEL=""

AZURE_FOUNDRY_MISTRAL_LARGE_ENDPOINT="https://xxxxx.services.ai.azure.com/openai/v1/"
AZURE_FOUNDRY_MISTRAL_LARGE_KEY="xxxxx"
AZURE_FOUNDRY_MISTRAL_LARGE_MODEL="Mistral-Large-3"

GROQ_ENDPOINT="https://api.groq.com/openai/v1"
GROQ_KEY="gsk_xxxxxxxx"
GROQ_LLAMA_MODEL="llama3-8b-8192"

OPEN_ROUTER_ENDPOINT="https://openrouter.ai/api/v1"
OPEN_ROUTER_KEY="sk-or-v1-xxxxx"
OPEN_ROUTER_CLAUDE_MODEL="anthropic/claude-3.7-sonnet"

OLLAMA_CHAT_ENDPOINT="http://127.0.0.1:11434/v1"
OLLAMA_MODEL="llama2"

DEFAULT_OPENAI_FRONTEND_ENDPOINT = ${AZURE_OPENAI_GPT4O_AAD_ENDPOINT}
DEFAULT_OPENAI_FRONTEND_KEY = ${AZURE_OPENAI_GPT4O_AAD_KEY}
DEFAULT_OPENAI_FRONTEND_MODEL = "gpt-4o"

OPENAI_CHAT_ENDPOINT=${PLATFORM_OPENAI_CHAT_ENDPOINT}
OPENAI_CHAT_KEY=${PLATFORM_OPENAI_CHAT_API_KEY}
OPENAI_CHAT_MODEL=${PLATFORM_OPENAI_CHAT_GPT4O_MODEL}
# The following line can be populated if using an Azure OpenAI deployment
# where the deployment name differs from the actual underlying model
OPENAI_CHAT_UNDERLYING_MODEL=""

##################################
# OPENAI RESPONSES TARGET SECRETS
##################################

AZURE_OPENAI_GPT5_RESPONSES_ENDPOINT="https://xxxxxxxxx.azure.com/openai/v1"
AZURE_OPENAI_GPT5_COMPLETION_ENDPOINT="https://xxxxxxxxx.azure.com/openai/v1"
AZURE_OPENAI_GPT5_KEY="xxxxxxx"
AZURE_OPENAI_GPT5_MODEL="gpt-5"
AZURE_OPENAI_GPT5_UNDERLYING_MODEL="gpt-5"

PLATFORM_OPENAI_RESPONSES_ENDPOINT="https://api.openai.com/v1"
PLATFORM_OPENAI_RESPONSES_KEY="sk-xxxxx"
PLATFORM_OPENAI_RESPONSES_MODEL="o4-mini"

AZURE_OPENAI_RESPONSES_ENDPOINT="https://xxxxx.openai.azure.com/openai/v1"
AZURE_OPENAI_RESPONSES_KEY="xxxxx"
AZURE_OPENAI_RESPONSES_MODEL="o4-mini"
AZURE_OPENAI_RESPONSES_UNDERLYING_MODEL="o4-mini"

OPENAI_RESPONSES_ENDPOINT=${PLATFORM_OPENAI_RESPONSES_ENDPOINT}
OPENAI_RESPONSES_KEY=${PLATFORM_OPENAI_RESPONSES_KEY}
OPENAI_RESPONSES_MODEL=${PLATFORM_OPENAI_RESPONSES_MODEL}
OPENAI_RESPONSES_UNDERLYING_MODEL=""

##################################
# OPENAI REALTIME TARGET SECRETS
#
# The below models work with RealtimeTarget - either pass via environment variables
# or copy to OPENAI_REALTIME_ENDPOINT
##################################

PLATFORM_OPENAI_REALTIME_ENDPOINT="wss://api.openai.com/v1"
PLATFORM_OPENAI_REALTIME_API_KEY="sk-xxxxx"
PLATFORM_OPENAI_REALTIME_MODEL="gpt-4o-realtime-preview"

AZURE_OPENAI_REALTIME_ENDPOINT = "wss://xxxx.openai.azure.com/openai/v1"
AZURE_OPENAI_REALTIME_API_KEY = "xxxxx"
AZURE_OPENAI_REALTIME_MODEL = "gpt-4o-realtime-preview"
AZURE_OPENAI_REALTIME_UNDERLYING_MODEL = "gpt-4o-realtime-preview"

OPENAI_REALTIME_ENDPOINT = ${PLATFORM_OPENAI_REALTIME_ENDPOINT}
OPENAI_REALTIME_API_KEY = ${PLATFORM_OPENAI_REALTIME_API_KEY}
OPENAI_REALTIME_MODEL = ${PLATFORM_OPENAI_REALTIME_MODEL}
OPENAI_REALTIME_UNDERLYING_MODEL = ""

##################################
# IMAGE TARGET SECRETS
#
# The below models work with OpenAIImageTarget - either pass via environment variables
# or copy to OPENAI_IMAGE_ENDPOINT
###################################

OPENAI_IMAGE_ENDPOINT1  = "https://xxxxx.openai.azure.com/openai/v1"
OPENAI_IMAGE_API_KEY1 = "xxxxxx"
OPENAI_IMAGE_MODEL1 = "deployment-name"
OPENAI_IMAGE_UNDERLYING_MODEL1 = "dall-e-3"

OPENAI_IMAGE_ENDPOINT2 = "https://api.openai.com/v1"
OPENAI_IMAGE_API_KEY2 = "sk-xxxxx"
OPENAI_IMAGE_MODEL2 = "dall-e-3"
OPENAI_IMAGE_UNDERLYING_MODEL2 = "dall-e-3"

OPENAI_IMAGE_ENDPOINT = ${OPENAI_IMAGE_ENDPOINT2}
OPENAI_IMAGE_API_KEY = ${OPENAI_IMAGE_API_KEY2}
OPENAI_IMAGE_MODEL = ${OPENAI_IMAGE_MODEL2}
OPENAI_IMAGE_UNDERLYING_MODEL = ""


##################################
# TTS TARGET SECRETS
#
# The below models work with OpenAITTSTarget - either pass via environment variables
# or copy to OPENAI_TTS_ENDPOINT
###################################

OPENAI_TTS_ENDPOINT1 = "https://xxxxx.openai.azure.com/openai/v1"
OPENAI_TTS_KEY1 = "xxxxxxx"
OPENAI_TTS_MODEL1 = "tts"
OPENAI_TTS_UNDERLYING_MODEL1 = "tts"

OPENAI_TTS_ENDPOINT2 = "https://api.openai.com/v1"
OPENAI_TTS_KEY2 = "xxxxxx"
OPENAI_TTS_MODEL2 = "tts-1"
OPENAI_TTS_UNDERLYING_MODEL2 = "tts-1"

OPENAI_TTS_ENDPOINT = ${OPENAI_TTS_ENDPOINT2}
OPENAI_TTS_KEY = ${OPENAI_TTS_KEY2}
OPENAI_TTS_MODEL = ${OPENAI_TTS_MODEL2}
OPENAI_TTS_UNDERLYING_MODEL = ""

##################################
# VIDEO TARGET SECRETS
#
# The below models work with OpenAIVideoTarget - either pass via environment variables
# or copy to OPENAI_VIDEO_ENDPOINT
###################################

# Note: Use the base URL without API path
AZURE_OPENAI_VIDEO_ENDPOINT="https://xxxxx.cognitiveservices.azure.com/openai/v1"
AZURE_OPENAI_VIDEO_KEY="xxxxxxx"
AZURE_OPENAI_VIDEO_MODEL="sora-2"
AZURE_OPENAI_VIDEO_UNDERLYING_MODEL="sora-2"

OPENAI_VIDEO_ENDPOINT = ${AZURE_OPENAI_VIDEO_ENDPOINT}
OPENAI_VIDEO_KEY = ${AZURE_OPENAI_VIDEO_KEY}
OPENAI_VIDEO_MODEL = ${AZURE_OPENAI_VIDEO_MODEL}
OPENAI_VIDEO_UNDERLYING_MODEL = ""


##################################
# AML TARGET SECRETS
# The below models work with AzureMLChatTarget - either pass via environment variables
# or copy to AZURE_ML_MANAGED_ENDPOINT
###################################

AZURE_ML_PHI_ENDPOINT="https://xxxxxx.westus3.inference.ml.azure.com/score"
AZURE_ML_PHI_KEY="xxxxx"

# The below is set as the default Azure OpenAI model used in most notebooks. Adjust as needed.
AZURE_ML_MANAGED_ENDPOINT=${AZURE_ML_PHI_ENDPOINT}
AZURE_ML_KEY=${AZURE_ML_PHI_KEY}


##################################
# MISC TARGET SECRETS
###################################


OPENAI_COMPLETION_ENDPOINT="https://xxxxx.openai.azure.com/openai/v1"
OPENAI_COMPLETION_API_KEY="xxxxx"
OPENAI_COMPLETION_MODEL="davinci-002"

OPENAI_EMBEDDING_ENDPOINT="https://xxxxx.openai.azure.com/openai/v1"
OPENAI_EMBEDDING_KEY="xxxxx"
OPENAI_EMBEDDING_MODEL="text-embedding-3-small"

AZURE_STORAGE_ACCOUNT_CONTAINER_URL="https://xxxxxx.blob.core.windows.net/xpia"
AZURE_STORAGE_ACCOUNT_SAS_TOKEN="xxxxx"


AZURE_SPEECH_REGION = "eastus2"
AZURE_SPEECH_KEY = "xxxxx"
# Resource ID is needed when using Entra authentication
AZURE_SPEECH_RESOURCE_ID = "xxxxx"

AZURE_CONTENT_SAFETY_API_KEY="xxxxx"
AZURE_CONTENT_SAFETY_API_ENDPOINT="https://xxxxx.cognitiveservices.azure.com/"

# If you're trying the challenges, not just running demos, you can get your own key here: https://crucible.dreadnode.io/login
CRUCIBLE_API_KEY = "xxxxx"

HUGGINGFACE_TOKEN="hf_xxxxxxx"

GOOGLE_GEMINI_ENDPOINT = "https://generativelanguage.googleapis.com/v1beta/openai"
GOOGLE_GEMINI_API_KEY = "xxxxx"
GOOGLE_GEMINI_MODEL="gemini-2.0-flash"


#########################
# AZURE SQL SECRETS
#########################


# This connects to the test database
AZURE_SQL_DB_CONNECTION_STRING_TEST = "mssql+pyodbc://@xxxxx.database.windows.net/xxxxx?driver=ODBC+Driver+18+for+SQL+Server"
AZURE_STORAGE_ACCOUNT_DB_DATA_CONTAINER_URL_TEST="https://xxxxx.blob.core.windows.net/dbdata"

# This connects to the prod database
AZURE_SQL_DB_CONNECTION_STRING_PROD = "mssql+pyodbc://@xxxxx.database.windows.net/xxxxx?driver=ODBC+Driver+18+for+SQL+Server"
AZURE_STORAGE_ACCOUNT_DB_DATA_CONTAINER_URL_PROD="https://xxxxx.blob.core.windows.net/dbdata"


# The below is set as the central memory. Adjust as needed. Recommend overwriting in .env.local.
AZURE_SQL_DB_CONNECTION_STRING = ${AZURE_SQL_DB_CONNECTION_STRING_PROD}
AZURE_STORAGE_ACCOUNT_DB_DATA_CONTAINER_URL=${AZURE_STORAGE_ACCOUNT_DB_DATA_CONTAINER_URL_PROD}
