# When External Data Becomes a Trojan Horse: 
*Published on February 15, 2025*

In an era where AI systems drive recruitment, recommendation engines, and critical decision-making processes, even the smallest piece of external data can be weaponized. In our latest project, we combined the **AI Recruiter** pipeline with the **XPIA Orchestrator**. We want to demonstrate a concerning vulnerability: external data injection. This blog post explains **exactly how an attacker might exploit such a system**—from crafting a manipulated résumé to triggering automated actions that could lead to phishing or even code execution.

---

## The Exploit in Detail: Step-by-Step

### 1. **Choosing the Target Job**
An attacker identifies a job posting they wish to apply for. They carefully review the required skills and qualifications, noting the key soft and hard skills mentioned in the job description.

### 2. **Crafting the Manipulated Résumé**
Instead of submitting a standard résumé, the attacker uses a **PDF converter** to inject hidden content into their CV. The same PDF converter is also an integral part of the XPIA Orchestrator's workflow, ensuring that the manipulation is both stealthy and effective. Here’s how it works:
- **Injection Technique:**  
  The attacker writes key phrases—both soft skills (e.g., "team leadership", "communication") and hard skills (e.g., "Python", "machine learning")—directly derived from the job description.
- **Stealth Injection:**  
  The text is injected using a very small, nearly invisible font size and the same font color as the CV background. This makes the injected text virtually undetectable to human reviewers while remaining fully readable by the AI system.

### 3. **Uploading via XPIA Orchestrator**
Once the résumé has been manipulated by the PDF converter, it is uploaded through the **XPIA Orchestrator**:
- **Automated Flow:**  
  The orchestrator takes over, automatically passing the résumé into the AI Recruiter pipeline. The system is designed to extract text, generate embeddings, and perform semantic matching against the job description.
- **Semantic Search Trigger:**  
  In the first phase, the AI recruiter conducts a semantic search among the top *k* candidates. Due to the injected keywords, the attacker’s résumé ends up with a very close semantic distance to the job description.

### 4. **AI Evaluation with GPT-4o**
The next stage involves in-depth evaluation:
- **Detailed Scoring:**  
  GPT-4o reviews the résumé and assigns a match score. Thanks to the strategically injected text, the manipulated résumé achieves a top score.
- **Potential Extended Capabilities:**  
  If GPT-4o is granted access to additional tools (such as web search, GitHub repository scanning, or code execution platforms), it could:
  - Follow links embedded in the résumé.
  - Retrieve more detailed information about the candidate.
  - Run or review code.
  - Generate feedback or forward a summary directly to HR.

### 5. **The Phishing Risk**
The consequences don’t end at evaluation:
- **Misleading Summaries & Links:**  
  The summary provided by GPT-4o could include links—perhaps directing HR to a GitHub repository controlled by the attacker. These links may appear legitimate and could be used for phishing.
- **Human Trust in AI:**  
  Since HR teams and decision-makers tend to trust AI-generated summaries and recommendations, these deceptive links can lead to further compromise, such as unauthorized code downloads or data breaches.

---

## Beyond Recruitment: The Broader Threat Landscape

While our demonstration focused on an AI-driven recruitment system, **the underlying vulnerability applies to any AI system that processes external data**. Consider these scenarios:
- **Malicious Code Execution:**  
  An injected link could direct the AI to download and run malicious scripts from a compromised GitHub repository.
- **Data Harvesting:**  
  The AI might be tricked into collecting internal data by following seemingly harmless external cues.
- **Manipulated Feedback Loops:**  
  Automated feedback or summaries could include harmful links or incorrect information, leading to compromised decision-making.

These scenarios illustrate how a carefully orchestrated external data injection can cascade into multiple forms of exploitation.

---

## Conclusion

Our demonstration with the XPIA Orchestrator and AI Recruiter pipeline highlights a critical vulnerability: **external data can be weaponized to manipulate AI systems**. An attacker can exploit this flaw by injecting hidden content into a résumé—ensuring a top semantic match and triggering further automated actions such as phishing attempts or malicious code execution.

As we integrate AI into more facets of our lives, it’s imperative to build systems that are not only intelligent but also secure. The time has come to view security as an integral part of AI design—ensuring that the data feeding into these systems is both trustworthy and safe.

---

**Explore More:**

- **XPIA Orchestrator Notebook:**  
  [View Notebook](../code/orchestrators/3_xpia_orchestrator.ipynb)
  
- **AI Recruiter Integration Tests:**  
  [View AI Recruiter Integration Test](../../tests/integration/ai_recruiter/test_ai_recruiter.py)

- **AI Recruiter Source Code:**  
  [View AI Recruiter Code](../../tests/integration/ai_recruiter/ai_recruiter.py)

