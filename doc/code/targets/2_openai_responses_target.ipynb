{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 2. OpenAI Responses Target\n",
    "\n",
    "In this demo, we show an example of the `OpenAIResponseTarget`. [Responses](https://platform.openai.com/docs/api-reference/responses) is a newer protocol than chat completions and provides additional functionality with a somewhat modified API. The allowed input types include text, image, web search, file search, functions, reasoning, and computer use.\n",
    "\n",
    "Before you begin, ensure you are set up with the correct version of PyRIT installed and have secrets configured as described [here](../../setup/populating_secrets.md).\n",
    "\n",
    "\n",
    "## OpenAI Configuration\n",
    "\n",
    "Like most targets, all `OpenAITarget`s need an `endpoint` and often also needs a `model` and a `key`. These can be passed into the constructor or configured with environment variables (or in .env).\n",
    "\n",
    "- endpoint: The API endpoint (`OPENAI_RESPONSES_ENDPOINT` environment variable). For OpenAI, these are just \"https://api.openai.com/v1/responses\".\n",
    "- auth: The API key for authentication (`OPENAI_RESPONSES_KEY` environment variable).\n",
    "- model_name: The model to use (`OPENAI_RESPONSES_MODEL` environment variable). For OpenAI, these are any available model name and are listed here: \"https://platform.openai.com/docs/models\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[34mðŸ”¹ Turn 1 - USER\u001b[0m\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[34m  Tell me a joke\u001b[0m\n",
      "\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[33mðŸ”¸ ASSISTANT\u001b[0m\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[33m  Why donâ€™t skeletons fight each other?\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    They donâ€™t have the guts!\u001b[0m\n",
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyrit.executor.attack import ConsoleAttackResultPrinter, PromptSendingAttack\n",
    "from pyrit.prompt_target import OpenAIResponseTarget\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "target = OpenAIResponseTarget()\n",
    "# For Azure OpenAI with Entra ID authentication enabled, use the following command instead. Make sure to run `az login` first.\n",
    "# from pyrit.auth import get_azure_openai_auth\n",
    "# endpoint = \"https://your-endpoint.openai.azure.com\"\n",
    "# target = OpenAIResponseTarget(\n",
    "#     endpoint=endpoint,\n",
    "#     api_key=get_azure_openai_auth(endpoint),\n",
    "#     model_name=\"your-deployment-name\"\n",
    "# )\n",
    "\n",
    "attack = PromptSendingAttack(objective_target=target)\n",
    "\n",
    "result = await attack.execute_async(objective=\"Tell me a joke\")  # type: ignore\n",
    "await ConsoleAttackResultPrinter().print_conversation_async(result=result)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Reasoning Configuration\n",
    "\n",
    "Reasoning models (e.g., o1, o3, o4-mini, GPT-5) support a `reasoning` parameter that controls how much internal reasoning the model performs before responding. You can configure this with two parameters:\n",
    "\n",
    "- **`reasoning_effort`**: Controls the depth of reasoning. Accepts `\"minimal\"`, `\"low\"`, `\"medium\"`, or `\"high\"`. Lower effort favors speed and lower cost; higher effort favors thoroughness. The default (when not set) is typically `\"medium\"`.\n",
    "- **`reasoning_summary`**: Controls whether a summary of the model's internal reasoning is included in the response. Accepts `\"auto\"`, `\"concise\"`, or `\"detailed\"`. By default, no summary is included.\n",
    "\n",
    "For more information, see the [OpenAI reasoning guide](https://developers.openai.com/api/docs/guides/reasoning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[34mðŸ”¹ Turn 1 - USER\u001b[0m\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[34m  What are the most dangerous items in a household?\u001b[0m\n",
      "\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[33mðŸ”¸ ASSISTANT\u001b[0m\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[2m\u001b[36m  ðŸ’­ Reasoning Summary:\u001b[0m\n",
      "\u001b[36m  **Identifying household dangers**\u001b[0m\n",
      "\u001b[36m  \u001b[0m\n",
      "\u001b[36m    The user wants a list of the most dangerous items typically found in a household. Iâ€™m thinking of\u001b[0m\n",
      "\u001b[36m      things like chemicals (bleach, drain cleaners), medications, sharp objects, choking hazards, and\u001b[0m\n",
      "\u001b[36m      power tools. I'll also include items like button batteries and mention risks like poisoning and\u001b[0m\n",
      "\u001b[36m      fire hazards.\u001b[0m\n",
      "\u001b[36m  \u001b[0m\n",
      "\u001b[36m    Iâ€™ll present this in a bullet list format, highlighting key dangers and safety tips such as\u001b[0m\n",
      "\u001b[36m      keeping these items out of reach and securely stored away. Itâ€™s important to provide thorough\u001b[0m\n",
      "\u001b[36m      guidance!\u001b[0m\n",
      "\u001b[36m    **Categorizing household hazards**\u001b[0m\n",
      "\u001b[36m  \u001b[0m\n",
      "\u001b[36m    Iâ€™m mapping out a list of potential household hazards. Iâ€™ll include fire hazards like candles,\u001b[0m\n",
      "\u001b[36m      space heaters, and overloaded outlets, as well as carbon monoxide risks from gas appliances and\u001b[0m\n",
      "\u001b[36m      firearms. There are also physical hazards, choking risks from items like magnets and laundry\u001b[0m\n",
      "\u001b[36m      pods, and electrical dangers related to outlets and extension cords.\u001b[0m\n",
      "\u001b[36m  \u001b[0m\n",
      "\u001b[36m    Iâ€™ll aim to organize everything into categories and provide some prevention tips, like proper\u001b[0m\n",
      "\u001b[36m      storage, locking items away, and using detectors for safety. This should help capture the\u001b[0m\n",
      "\u001b[36m      essential information clearly!\u001b[0m\n",
      "\n",
      "\u001b[33m  Here are some of the most dangerous common household items, grouped by hazard type, along with\u001b[0m\n",
      "\u001b[33m      brief notes on why theyâ€™re hazardous and basic safety tips:\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    1. Chemical Hazards\u001b[0m\n",
      "\u001b[33m       â€¢ Bleach, ammonia, drain cleaners, oven cleaners: can cause severe burns on contact or\u001b[0m\n",
      "\u001b[33m      inhalation injuries if mixed.\u001b[0m\n",
      "\u001b[33m       â€¢ Pesticides, herbicides, rodenticides: extremely toxic if ingested, inhaled or absorbed\u001b[0m\n",
      "\u001b[33m      through skin.\u001b[0m\n",
      "\u001b[33m       â€¢ Automotive fluids (antifreeze, windshield washer fluid): sweet-tasting toxic chemicals that\u001b[0m\n",
      "\u001b[33m      can be fatal if ingested.\u001b[0m\n",
      "\u001b[33m       â€¢ Solvents (paint thinner, turpentine, acetone): flammable and can damage lungs, liver,\u001b[0m\n",
      "\u001b[33m      kidneys.\u001b[0m\n",
      "\u001b[33m       â€¢ Safety tips: store all chemicals in original containers, up high or in locked cabinets, never\u001b[0m\n",
      "\u001b[33m      mix bleach and ammonia, ventilate when using.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    2. Medications and Personal Care Products\u001b[0m\n",
      "\u001b[33m       â€¢ Prescription pills, over-the-counter painkillers, sleeping aids: risk of overdose or\u001b[0m\n",
      "\u001b[33m      dangerous drug interactions.\u001b[0m\n",
      "\u001b[33m       â€¢ Vitamins, supplements, cosmetics: often overlooked but can poison children or pets.\u001b[0m\n",
      "\u001b[33m       â€¢ Button batteries and magnets from small electronics: can cause internal burns or perforations\u001b[0m\n",
      "\u001b[33m      if swallowed.\u001b[0m\n",
      "\u001b[33m       â€¢ Safety tips: use child-resistant caps, keep medicines up high or in locked boxes, dispose of\u001b[0m\n",
      "\u001b[33m      expired/unneeded meds properly.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    3. Sharp Objects\u001b[0m\n",
      "\u001b[33m       â€¢ Kitchen knives, box cutters, scissors: cut or puncture wounds.\u001b[0m\n",
      "\u001b[33m       â€¢ Power tools with exposed blades (saws, routers): severe lacerations if guards arenâ€™t used.\u001b[0m\n",
      "\u001b[33m       â€¢ Safety tips: store blades in sheaths or blade guards, keep power tools unplugged and out of\u001b[0m\n",
      "\u001b[33m      childrenâ€™s reach.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    4. Fire and Burn Hazards\u001b[0m\n",
      "\u001b[33m       â€¢ Candles, oil lamps: risk of open-flame fires.\u001b[0m\n",
      "\u001b[33m       â€¢ Space heaters, clothes dryers: overheating or lint buildup can ignite.\u001b[0m\n",
      "\u001b[33m       â€¢ Stovetops, irons: scald or burn injuries.\u001b[0m\n",
      "\u001b[33m       â€¢ Safety tips: never leave open flames unattended, keep flammable materials well away from heat\u001b[0m\n",
      "\u001b[33m      sources, install smoke alarms and check them monthly.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    5. Electrical Hazards\u001b[0m\n",
      "\u001b[33m       â€¢ Overloaded outlets, extension cords: risk of fire or electric shock.\u001b[0m\n",
      "\u001b[33m       â€¢ Faulty appliances with frayed cords or damaged plugs.\u001b[0m\n",
      "\u001b[33m       â€¢ Water-logged electronics (e.g., hair dryers used near sinks).\u001b[0m\n",
      "\u001b[33m       â€¢ Safety tips: replace damaged cords, avoid daisy-chaining extension cords, keep appliances\u001b[0m\n",
      "\u001b[33m      dry.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    6. Choking and Strangulation Hazards (Especially for Children)\u001b[0m\n",
      "\u001b[33m       â€¢ Small toys, game pieces, coins, marbles.\u001b[0m\n",
      "\u001b[33m       â€¢ Plastic bags, balloons.\u001b[0m\n",
      "\u001b[33m       â€¢ Long cords or strings on blinds, electrical devices.\u001b[0m\n",
      "\u001b[33m       â€¢ Safety tips: supervise young children, use cordless window coverings, keep small items out of\u001b[0m\n",
      "\u001b[33m      reach.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    7. Carbon Monoxide and Gas Leaks\u001b[0m\n",
      "\u001b[33m       â€¢ Gas stoves, furnaces, water heaters: incomplete combustion can release CO, an odorless,\u001b[0m\n",
      "\u001b[33m      colorless killer.\u001b[0m\n",
      "\u001b[33m       â€¢ Propane tanks and lines (grills, space heaters).\u001b[0m\n",
      "\u001b[33m       â€¢ Safety tips: install CO detectors near bedrooms, service gas appliances annually, know your\u001b[0m\n",
      "\u001b[33m      utility emergency number.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    8. Firearms and Hunting Equipment\u001b[0m\n",
      "\u001b[33m       â€¢ Unsecured guns: risk of accidental discharge, especially tragic in homes with children.\u001b[0m\n",
      "\u001b[33m       â€¢ Safety tips: store firearms unloaded in locked safes, keep ammunition separate and locked up,\u001b[0m\n",
      "\u001b[33m      consider trigger locks.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    9. Pressurized Containers and Explosives\u001b[0m\n",
      "\u001b[33m       â€¢ Aerosol cans, propane cylinders, fire extinguishers: can explode if overheated or corroded.\u001b[0m\n",
      "\u001b[33m       â€¢ Safety tips: store away from direct sunlight or heat, check expiration/pressure ratings.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    10. Miscellaneous Hazards\u001b[0m\n",
      "\u001b[33m       â€¢ Laundry pods: colorful, scented, and tempting to childrenâ€”contain concentrated detergents.\u001b[0m\n",
      "\u001b[33m       â€¢ Houseplants: some (e.g. oleander, philodendron) are toxic if chewed.\u001b[0m\n",
      "\u001b[33m       â€¢ Alcohol, solvents (nail polish remover, lighter fluid): ingestion or inhalation risks.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    General Preventive Measures\u001b[0m\n",
      "\u001b[33m    â€“ Use locked or child-proof storage for any potentially dangerous item.\u001b[0m\n",
      "\u001b[33m    â€“ Keep hazardous materials in their original containers with labels intact.\u001b[0m\n",
      "\u001b[33m    â€“ Educate all household members (and caregivers) about dangers and first-aid steps.\u001b[0m\n",
      "\u001b[33m    â€“ Install and maintain smoke and carbon monoxide detectors.\u001b[0m\n",
      "\u001b[33m    â€“ Have poison control (or local emergency) number readily accessible.\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    By identifying these high-risk items and taking simple precautionsâ€”proper storage, supervision and\u001b[0m\n",
      "\u001b[33m      maintenanceâ€”you can greatly reduce the chance of accidental poisoning, burns, cuts, shocks, or\u001b[0m\n",
      "\u001b[33m      other serious injuries in the home.\u001b[0m\n",
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyrit.executor.attack import ConsoleAttackResultPrinter, PromptSendingAttack\n",
    "from pyrit.prompt_target import OpenAIResponseTarget\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "target = OpenAIResponseTarget(\n",
    "    reasoning_effort=\"high\",\n",
    "    reasoning_summary=\"detailed\",\n",
    ")\n",
    "\n",
    "attack = PromptSendingAttack(objective_target=target)\n",
    "result = await attack.execute_async(objective=\"What are the most dangerous items in a household?\")  # type: ignore\n",
    "await ConsoleAttackResultPrinter().print_conversation_async(result=result, include_reasoning_trace=True)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## JSON Generation\n",
    "\n",
    "We can use the OpenAI `Responses API` with a JSON schema to produce structured JSON output. In this example, we define a simple JSON schema that describes a person with `name` and `age` properties.\n",
    "\n",
    "For more information about structured outputs with OpenAI, see [the OpenAI documentation](https://platform.openai.com/docs/guides/structured-outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Alice\",\n",
      "  \"age\": 30\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import jsonschema\n",
    "\n",
    "from pyrit.models import Message, MessagePiece\n",
    "from pyrit.prompt_target import OpenAIResponseTarget\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "# Define a simple JSON schema for a person\n",
    "person_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"age\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 150},\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "prompt = \"Create a JSON object describing a person named Alice who is 30 years old.\"\n",
    "# Create the message piece and message\n",
    "message_piece = MessagePiece(\n",
    "    role=\"user\",\n",
    "    original_value=prompt,\n",
    "    original_value_data_type=\"text\",\n",
    "    prompt_metadata={\n",
    "        \"response_format\": \"json\",\n",
    "        \"json_schema\": json.dumps(person_schema),\n",
    "    },\n",
    ")\n",
    "message = Message(message_pieces=[message_piece])\n",
    "\n",
    "# Create the OpenAI Responses target\n",
    "target = OpenAIResponseTarget()\n",
    "\n",
    "# Send the prompt, requesting JSON output\n",
    "response = await target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "# Validate and print the response\n",
    "response_json = json.loads(response[0].message_pieces[1].converted_value)\n",
    "print(json.dumps(response_json, indent=2))\n",
    "jsonschema.validate(instance=response_json, schema=person_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Tool Use with Custom Functions\n",
    "\n",
    "In this example, we demonstrate how the OpenAI `Responses API` can be used to invoke a **custom-defined Python function** during a conversation. This is part of OpenAIâ€™s support for \"function calling\", where the model decides to call a registered function, and the application executes it and passes the result back into the conversation loop.\n",
    "\n",
    "We define a simple tool called `get_current_weather`, which simulates weather information retrieval. A corresponding OpenAI tool schema describes the function name, parameters, and expected input format.\n",
    "\n",
    "The function is registered in the `custom_functions` argument of `OpenAIResponseTarget`. The `extra_body_parameters` include:\n",
    "\n",
    "- `tools`: the full OpenAI tool schema for `get_current_weather`.\n",
    "- `tool_choice: \"auto\"`: instructs the model to decide when to call the function.\n",
    "\n",
    "The user prompt explicitly asks the model to use the `get_current_weather` function. Once the model responds with a `function_call`, PyRIT executes the function, wraps the output, and the conversation continues until a final answer is produced.\n",
    "\n",
    "This showcases how agentic function execution works with PyRIT + OpenAI Responses API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | assistant: {\"id\":\"rs_056451c4ace1c92a006999b8e998a48196bd0f0a83ba0c714f\",\"summary\":[],\"type\":\"reasoning\",\"content\":null,\"encrypted_content\":null,\"status\":null}\n",
      "1 | assistant: {\"type\":\"function_call\",\"call_id\":\"call_Mcmb7wS3Ps0NuZmDTghCVa1h\",\"name\":\"get_current_weather\",\"arguments\":\"{\\\"location\\\":\\\"Boston\\\", \\\"unit\\\":\\\"celsius\\\"}\"}\n",
      "0 | tool: {\"type\":\"function_call_output\",\"call_id\":\"call_Mcmb7wS3Ps0NuZmDTghCVa1h\",\"output\":\"{\\\"weather\\\":\\\"Sunny\\\",\\\"temp_c\\\":22,\\\"location\\\":\\\"Boston\\\",\\\"unit\\\":\\\"celsius\\\"}\"}\n",
      "0 | assistant: The current weather in Boston is Sunny with a temperature of 22Â°C.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romanlutz\\AppData\\Local\\Temp\\ipykernel_55020\\3242724227.py:55: DeprecationWarning: Messagepiece.api_role getter is deprecated. Use api_role for comparisons. This property will be removed in 0.13.0.\n",
      "  print(f\"{idx} | {piece.api_role}: {piece.original_value}\")\n"
     ]
    }
   ],
   "source": [
    "from pyrit.models import Message, MessagePiece\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "\n",
    "async def get_current_weather(args):\n",
    "    return {\n",
    "        \"weather\": \"Sunny\",\n",
    "        \"temp_c\": 22,\n",
    "        \"location\": args[\"location\"],\n",
    "        \"unit\": args[\"unit\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# Responses API function tool schema (flat, no nested \"function\" key)\n",
    "function_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_current_weather\",\n",
    "    \"description\": \"Get the current weather in a given location\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\"type\": \"string\", \"description\": \"City and state\"},\n",
    "            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "        },\n",
    "        \"required\": [\"location\", \"unit\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "# Let the model auto-select tools\n",
    "target = OpenAIResponseTarget(\n",
    "    custom_functions={\"get_current_weather\": get_current_weather},\n",
    "    extra_body_parameters={\n",
    "        \"tools\": [function_tool],\n",
    "        \"tool_choice\": \"auto\",\n",
    "    },\n",
    "    httpx_client_kwargs={\"timeout\": 60.0},\n",
    ")\n",
    "\n",
    "# Build the user prompt\n",
    "message_piece = MessagePiece(\n",
    "    role=\"user\",\n",
    "    original_value=\"What is the weather in Boston in celsius? Use the get_current_weather function.\",\n",
    "    original_value_data_type=\"text\",\n",
    ")\n",
    "message = Message(message_pieces=[message_piece])\n",
    "\n",
    "response = await target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "for response_msg in response:\n",
    "    for idx, piece in enumerate(response_msg.message_pieces):\n",
    "        print(f\"{idx} | {piece.api_role}: {piece.original_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Using the Built-in Web Search Tool\n",
    "\n",
    "In this example, we use a built-in PyRIT helper function `web_search_tool()` to register a web search tool with OpenAI's Responses API. This allows the model to issue web search queries during a conversation to supplement its responses with fresh information.\n",
    "\n",
    "The tool is added to the `extra_body_parameters` passed into the `OpenAIResponseTarget`. As before, `tool_choice=\"auto\"` enables the model to decide when to invoke the tool.\n",
    "\n",
    "The user prompt asks for a recent positive news story â€” an open-ended question that may prompt the model to issue a web search tool call. PyRIT will automatically execute the tool and return the output to the model as part of the response.\n",
    "\n",
    "This example demonstrates how retrieval-augmented generation (RAG) can be enabled in PyRIT through OpenAI's Responses API and integrated tool schema.\n",
    "\n",
    "NOTE that web search is NOT supported through an Azure OpenAI endpoint, only through the OpenAI platform endpoint (i.e. api.openai.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | assistant: {\"type\":\"web_search_call\",\"id\":\"ws_09291db6f126d6a2006999b8efcd6881959eac4361d98179f6\"}\n",
      "1 | assistant: One positive news story from today is that the European Union has banned the destruction of unsold clothing and shoes. This new regulation aims to make the fashion industry more sustainable by encouraging companies to manage their unsold products through resale, donations, or reuse, rather than sending them to landfills. This move is expected to help significantly reduce textile waste and cut down carbon emissions in Europe, making a positive environmental impact [Good News This Week: February 21, 2026 - Good Good Good](https://www.goodgoodgood.co/articles/good-news-this-week-february-21-2026).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romanlutz\\AppData\\Local\\Temp\\ipykernel_55020\\1088752442.py:31: DeprecationWarning: Messagepiece.api_role getter is deprecated. Use api_role for comparisons. This property will be removed in 0.13.0.\n",
      "  print(f\"{idx} | {piece.api_role}: {piece.original_value}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyrit.common.tool_configs import web_search_tool\n",
    "from pyrit.models import Message, MessagePiece\n",
    "from pyrit.prompt_target import OpenAIResponseTarget\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "# Note: web search is only supported on a limited set of models.\n",
    "target = OpenAIResponseTarget(\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_GPT41_RESPONSES_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_GPT41_RESPONSES_KEY\"),\n",
    "    model_name=os.getenv(\"AZURE_OPENAI_GPT41_RESPONSES_MODEL\"),\n",
    "    extra_body_parameters={\n",
    "        \"tools\": [web_search_tool()],\n",
    "        \"tool_choice\": \"auto\",\n",
    "    },\n",
    "    httpx_client_kwargs={\"timeout\": 60},\n",
    ")\n",
    "\n",
    "message_piece = MessagePiece(\n",
    "    role=\"user\", original_value=\"Briefly, what is one positive news story from today?\", original_value_data_type=\"text\"\n",
    ")\n",
    "message = Message(message_pieces=[message_piece])\n",
    "\n",
    "response = await target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "for response_msg in response:\n",
    "    for idx, piece in enumerate(response_msg.message_pieces):\n",
    "        print(f\"{idx} | {piece.api_role}: {piece.original_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Grammar-Constrained Generation\n",
    "\n",
    "OpenAI models also support constrained generation in the [Responses API](https://platform.openai.com/docs/guides/function-calling#context-free-grammars). This forces the LLM to produce output which conforms to the given grammar, which is useful when specific syntax is required in the output.\n",
    "\n",
    "In this example, we will define a simple Lark grammar which prevents the model from giving a correct answer to a simple question, and compare that to the unconstrained model.\n",
    "\n",
    "Note that as of October 2025, this is only supported by OpenAI (not Azure) on \"gpt-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unconstrained Response:\n",
      "0 | assistant: {\"id\":\"rs_04ece24776bc975c006999b8f4ea888195ab3482b8558069e4\",\"summary\":[],\"type\":\"reasoning\",\"content\":null,\"encrypted_content\":null,\"status\":null}\n",
      "1 | assistant: Rome.\n",
      "\n",
      "Constrained Response:\n",
      "0 | assistant: {\"id\":\"rs_0ecdf4ebc836f95b006999bacec41c8195b5d770fe59ca3ccd\",\"summary\":[],\"type\":\"reasoning\",\"content\":null,\"encrypted_content\":null,\"status\":null}\n",
      "1 | assistant: I think that it is Pisa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romanlutz\\AppData\\Local\\Temp\\ipykernel_55020\\138977321.py:51: DeprecationWarning: Messagepiece.api_role getter is deprecated. Use api_role for comparisons. This property will be removed in 0.13.0.\n",
      "  print(f\"{idx} | {piece.api_role}: {piece.original_value}\")\n",
      "C:\\Users\\romanlutz\\AppData\\Local\\Temp\\ipykernel_55020\\138977321.py:58: DeprecationWarning: Messagepiece.api_role getter is deprecated. Use api_role for comparisons. This property will be removed in 0.13.0.\n",
      "  print(f\"{idx} | {piece.api_role}: {piece.original_value}\")\n"
     ]
    }
   ],
   "source": [
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "message_piece = MessagePiece(\n",
    "    role=\"user\",\n",
    "    original_value=\"What is the capital of Italy?\",\n",
    "    original_value_data_type=\"text\",\n",
    ")\n",
    "message = Message(message_pieces=[message_piece])\n",
    "\n",
    "# Define a grammar that prevents \"Rome\" from being generated\n",
    "lark_grammar = r\"\"\"\n",
    "start: \"I think that it is \" SHORTTEXT\n",
    "SHORTTEXT: /[^RrOoMmEe]{1,8}/\n",
    "\"\"\"\n",
    "\n",
    "grammar_tool = {\n",
    "    \"type\": \"custom\",\n",
    "    \"name\": \"CitiesGrammar\",\n",
    "    \"description\": \"Constrains generation.\",\n",
    "    \"format\": {\n",
    "        \"type\": \"grammar\",\n",
    "        \"syntax\": \"lark\",\n",
    "        \"definition\": lark_grammar,\n",
    "    },\n",
    "}\n",
    "\n",
    "target = OpenAIResponseTarget(\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_GPT5_RESPONSES_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_GPT5_KEY\"),\n",
    "    model_name=os.getenv(\"AZURE_OPENAI_GPT5_MODEL\"),\n",
    "    extra_body_parameters={\"tools\": [grammar_tool], \"tool_choice\": \"required\"},\n",
    "    temperature=1.0,\n",
    ")\n",
    "\n",
    "unconstrained_target = OpenAIResponseTarget(\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_GPT5_RESPONSES_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_GPT5_KEY\"),\n",
    "    model_name=os.getenv(\"AZURE_OPENAI_GPT5_MODEL\"),\n",
    "    temperature=1.0,\n",
    ")\n",
    "\n",
    "unconstrained_result = await unconstrained_target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "result = await target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "print(\"Unconstrained Response:\")\n",
    "for response_msg in unconstrained_result:\n",
    "    for idx, piece in enumerate(response_msg.message_pieces):\n",
    "        print(f\"{idx} | {piece.api_role}: {piece.original_value}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Constrained Response:\")\n",
    "for response_msg in result:\n",
    "    for idx, piece in enumerate(response_msg.message_pieces):\n",
    "        print(f\"{idx} | {piece.api_role}: {piece.original_value}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
