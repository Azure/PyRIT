{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 2. OpenAI Responses Target\n",
    "\n",
    "In this demo, we show an example of the `OpenAIResponseTarget`. [Responses](https://platform.openai.com/docs/api-reference/responses) is a newer protocol than chat completions and provides additional functionality with a somewhat modified API. The allowed input types include text, image, web search, file search, functions, reasoning, and computer use.\n",
    "\n",
    "Before you begin, ensure you are set up with the correct version of PyRIT installed and have secrets configured as described [here](../../setup/populating_secrets.md).\n",
    "\n",
    "\n",
    "## OpenAI Configuration\n",
    "\n",
    "Like most targets, all `OpenAITarget`s need an `endpoint` and often also needs a `model` and a `key`. These can be passed into the constructor or configured with environment variables (or in .env).\n",
    "\n",
    "- endpoint: The API endpoint (`OPENAI_RESPONSES_ENDPOINT` environment variable). For OpenAI, these are just \"https://api.openai.com/v1/responses\".\n",
    "- auth: The API key for authentication (`OPENAI_RESPONSES_KEY` environment variable).\n",
    "- model_name: The model to use (`OPENAI_RESPONSES_MODEL` environment variable). For OpenAI, these are any available model name and are listed here: \"https://platform.openai.com/docs/models\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[34mğŸ”¹ Turn 1 - USER\u001b[0m\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[34m  Tell me a joke\u001b[0m\n",
      "\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[33mğŸ”¸ ASSISTANT\u001b[0m\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[33m  Why did the scarecrow win an award?\u001b[0m\n",
      "\u001b[33m    Because he was outstanding in his field!\u001b[0m\n",
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyrit.executor.attack import ConsoleAttackResultPrinter, PromptSendingAttack\n",
    "from pyrit.prompt_target import OpenAIResponseTarget\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "target = OpenAIResponseTarget()\n",
    "# For Azure OpenAI with Entra ID authentication enabled, use the following command instead. Make sure to run `az login` first.\n",
    "# from pyrit.auth import get_azure_openai_auth\n",
    "# endpoint = \"https://your-endpoint.openai.azure.com\"\n",
    "# target = OpenAIResponseTarget(\n",
    "#     endpoint=endpoint,\n",
    "#     api_key=get_azure_openai_auth(endpoint),\n",
    "#     model_name=\"your-deployment-name\"\n",
    "# )\n",
    "\n",
    "attack = PromptSendingAttack(objective_target=target)\n",
    "\n",
    "result = await attack.execute_async(objective=\"Tell me a joke\")  # type: ignore\n",
    "await ConsoleAttackResultPrinter().print_conversation_async(result=result)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Reasoning Configuration\n",
    "\n",
    "Reasoning models (e.g., o1, o3, o4-mini, GPT-5) support a `reasoning` parameter that controls how much internal reasoning the model performs before responding. You can configure this with two parameters:\n",
    "\n",
    "- **`reasoning_effort`**: Controls the depth of reasoning. Accepts `\"minimal\"`, `\"low\"`, `\"medium\"`, or `\"high\"`. Lower effort favors speed and lower cost; higher effort favors thoroughness. The default (when not set) is typically `\"medium\"`.\n",
    "- **`reasoning_summary`**: Controls whether a summary of the model's internal reasoning is included in the response. Accepts `\"auto\"`, `\"concise\"`, or `\"detailed\"`. By default, no summary is included.\n",
    "\n",
    "For more information, see the [OpenAI reasoning guide](https://developers.openai.com/api/docs/guides/reasoning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[34mğŸ”¹ Turn 1 - USER\u001b[0m\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[34m  What are the most dangerous items in a household?\u001b[0m\n",
      "\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[33mğŸ”¸ ASSISTANT\u001b[0m\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[2m\u001b[36m  ğŸ’­ Reasoning Summary:\u001b[0m\n",
      "\u001b[36m  **Identifying household dangers**\u001b[0m\n",
      "\u001b[36m  \u001b[0m\n",
      "\u001b[36m    The user wants to know about the most dangerous items in a household, including potential hazards\u001b[0m\n",
      "\u001b[36m      like knives, cleaning products, medications, and small objects. There are several categories to\u001b[0m\n",
      "\u001b[36m      consider. For chemical hazards, items like cleaning supplies and medications can cause\u001b[0m\n",
      "\u001b[36m      poisoning. Sharp objects and fire hazards include knives and flammable liquids. Electrical\u001b[0m\n",
      "\u001b[36m      hazards involve old wiring and overloaded outlets. Toys can be choking hazards, and furniture\u001b[0m\n",
      "\u001b[36m      can tip over, causing injury. I can outline the severity and potential injuries of these items.\u001b[0m\n",
      "\u001b[36m    **Listing household hazards**\u001b[0m\n",
      "\u001b[36m  \u001b[0m\n",
      "\u001b[36m    Iâ€™m putting together a list of potentially dangerous household items ranging from cleaning\u001b[0m\n",
      "\u001b[36m      products and medications to sharp objects and fire hazards. Iâ€™ve identified categories worth\u001b[0m\n",
      "\u001b[36m      noting. Cleaning chemicals like bleach and ammonia can be harmful, along with medicines and\u001b[0m\n",
      "\u001b[36m      pesticides. Sharp objects such as knives pose risks, as do fire hazards like lighters and space\u001b[0m\n",
      "\u001b[36m      heaters. Iâ€™ll also include electrical hazards, heavy furniture, small objects, and flammable\u001b[0m\n",
      "\u001b[36m      liquids. I'll propose a ranked list with enough tips and cautions for the user!\u001b[0m\n",
      "\u001b[33m  Hereâ€™s a broad overview of some of the most hazardous everyday items youâ€™re likely to find around\u001b[0m\n",
      "\u001b[33m      the home, organized by the type of risk they pose:\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    1. Cleaning Chemicals and Solvents\u001b[0m\n",
      "\u001b[33m      â€¢ Bleach, ammonia and drainâ€ and ovenâ€cleaners (highly caustic; can burn skin and eyes)\u001b[0m\n",
      "\u001b[33m      â€¢ Toiletâ€bowl cleaners (acidic or caustic)\u001b[0m\n",
      "\u001b[33m      â€¢ Paint thinners, turpentine, nailâ€polish removers (toxic if inhaled/ingested; flammable)\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    2. Pesticides, Herbicides & Automotive Fluids\u001b[0m\n",
      "\u001b[33m      â€¢ Insect sprays, rodenticides, weedâ€killers (poisoning risk)\u001b[0m\n",
      "\u001b[33m      â€¢ Antifreeze (ethylene glycol is sweetÂ­-tasting but highly toxic)\u001b[0m\n",
      "\u001b[33m      â€¢ Gasoline, kerosene, paint stripper (poisonous vapors; extreme fire hazard)\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    3. Medications & Vitamins\u001b[0m\n",
      "\u001b[33m      â€¢ Prescription painkillers, antidepressants, sedatives (overdose risk)\u001b[0m\n",
      "\u001b[33m      â€¢ Over-the-counter pain relievers (especially acetaminophen), iron supplements (liver toxicity)\u001b[0m\n",
      "\u001b[33m      â€¢ Childrenâ€™s chewables or gummies (easy for little ones to mistake for candy)\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    4. Sharp Objects\u001b[0m\n",
      "\u001b[33m      â€¢ Kitchen knives, scissors, boxâ€cutters, utility blades\u001b[0m\n",
      "\u001b[33m      â€¢ Broken glass, ceramic, or mirrors\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    5. Fire and Burn Hazards\u001b[0m\n",
      "\u001b[33m      â€¢ Matches, lighters, candles, oil lamps\u001b[0m\n",
      "\u001b[33m      â€¢ Portable heaters, space heaters, clothes irons, curling irons\u001b[0m\n",
      "\u001b[33m      â€¢ Oven, stovetop, toaster ovens (hot surfaces and hot liquids)\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    6. Electrical Hazards\u001b[0m\n",
      "\u001b[33m      â€¢ Frayed extension cords, overloaded power strips\u001b[0m\n",
      "\u001b[33m      â€¢ Ungrounded or outdated wiring in outlets\u001b[0m\n",
      "\u001b[33m      â€¢ Faulty appliances (toasters, hair dryers)\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    7. Tools and Machinery\u001b[0m\n",
      "\u001b[33m      â€¢ Power tools: circular saws, drills, sanders (laceration/amputation risks)\u001b[0m\n",
      "\u001b[33m      â€¢ Ladders (falls from height)\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    8. Heavy or Tip-Over Risks\u001b[0m\n",
      "\u001b[33m      â€¢ Tall dressers, bookcases, TVs not anchored to the wall (crush injuries)\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    9. Small Parts & Choking Hazards\u001b[0m\n",
      "\u001b[33m      â€¢ Button batteries (rapid, severe internal burns if swallowed)\u001b[0m\n",
      "\u001b[33m      â€¢ Small toy pieces, coins, marbles\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    10. Plastic Bags & Wrappings\u001b[0m\n",
      "\u001b[33m      â€¢ Suffocation risk for infants and small children\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    11. Household Plants & Biohazards\u001b[0m\n",
      "\u001b[33m      â€¢ Common indoor plants (e.g. philodendron, dieffenbachia, oleander) can be toxic if chewed\u001b[0m\n",
      "\u001b[33m      â€¢ Mold growth in damp areas (allergens, respiratory irritants)\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    12. Firearms & Ammunition\u001b[0m\n",
      "\u001b[33m      â€¢ If present, always keep unloaded, locked and separate from ammo\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    13. Carbon Monoxide Sources\u001b[0m\n",
      "\u001b[33m      â€¢ Gas furnaces, water heaters, fireplaces, charcoal grills used indoors (odorless, colorless gas\u001b[0m\n",
      "\u001b[33m      can be fatal)\u001b[0m\n",
      "\u001b[33m  \u001b[0m\n",
      "\u001b[33m    By being aware of where these items are stored and who has access to them, you can take simple\u001b[0m\n",
      "\u001b[33m      stepsâ€”like using child-proof locks, keeping chemicals in original, clearly labeled containers,\u001b[0m\n",
      "\u001b[33m      anchoring heavy furniture, installing smoke/carbon-monoxide detectors, and maintaining\u001b[0m\n",
      "\u001b[33m      appliancesâ€”to dramatically reduce the risk of serious injury or poisoning in your home.\u001b[0m\n",
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyrit.executor.attack import ConsoleAttackResultPrinter, PromptSendingAttack\n",
    "from pyrit.prompt_target import OpenAIResponseTarget\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "target = OpenAIResponseTarget(\n",
    "    reasoning_effort=\"high\",\n",
    "    reasoning_summary=\"detailed\",\n",
    ")\n",
    "\n",
    "attack = PromptSendingAttack(objective_target=target)\n",
    "result = await attack.execute_async(objective=\"What are the most dangerous items in a household?\")  # type: ignore\n",
    "await ConsoleAttackResultPrinter().print_conversation_async(result=result)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## JSON Generation\n",
    "\n",
    "We can use the OpenAI `Responses API` with a JSON schema to produce structured JSON output. In this example, we define a simple JSON schema that describes a person with `name` and `age` properties.\n",
    "\n",
    "For more information about structured outputs with OpenAI, see [the OpenAI documentation](https://platform.openai.com/docs/guides/structured-outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Alice\",\n",
      "  \"age\": 30\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import jsonschema\n",
    "\n",
    "from pyrit.models import Message, MessagePiece\n",
    "from pyrit.prompt_target import OpenAIResponseTarget\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "# Define a simple JSON schema for a person\n",
    "person_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"age\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 150},\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"],\n",
    "    \"additionalProperties\": False,\n",
    "}\n",
    "\n",
    "prompt = \"Create a JSON object describing a person named Alice who is 30 years old.\"\n",
    "# Create the message piece and message\n",
    "message_piece = MessagePiece(\n",
    "    role=\"user\",\n",
    "    original_value=prompt,\n",
    "    original_value_data_type=\"text\",\n",
    "    prompt_metadata={\n",
    "        \"response_format\": \"json\",\n",
    "        \"json_schema\": json.dumps(person_schema),\n",
    "    },\n",
    ")\n",
    "message = Message(message_pieces=[message_piece])\n",
    "\n",
    "# Create the OpenAI Responses target\n",
    "target = OpenAIResponseTarget()\n",
    "\n",
    "# Send the prompt, requesting JSON output\n",
    "response = await target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "# Validate and print the response\n",
    "response_json = json.loads(response[0].message_pieces[1].converted_value)\n",
    "print(json.dumps(response_json, indent=2))\n",
    "jsonschema.validate(instance=response_json, schema=person_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Tool Use with Custom Functions\n",
    "\n",
    "In this example, we demonstrate how the OpenAI `Responses API` can be used to invoke a **custom-defined Python function** during a conversation. This is part of OpenAIâ€™s support for \"function calling\", where the model decides to call a registered function, and the application executes it and passes the result back into the conversation loop.\n",
    "\n",
    "We define a simple tool called `get_current_weather`, which simulates weather information retrieval. A corresponding OpenAI tool schema describes the function name, parameters, and expected input format.\n",
    "\n",
    "The function is registered in the `custom_functions` argument of `OpenAIResponseTarget`. The `extra_body_parameters` include:\n",
    "\n",
    "- `tools`: the full OpenAI tool schema for `get_current_weather`.\n",
    "- `tool_choice: \"auto\"`: instructs the model to decide when to call the function.\n",
    "\n",
    "The user prompt explicitly asks the model to use the `get_current_weather` function. Once the model responds with a `function_call`, PyRIT executes the function, wraps the output, and the conversation continues until a final answer is produced.\n",
    "\n",
    "This showcases how agentic function execution works with PyRIT + OpenAI Responses API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | assistant: {\"id\":\"rs_0e14bf469480a927006999b438e8208197a9861893bcf110f9\",\"summary\":[],\"type\":\"reasoning\",\"content\":null,\"encrypted_content\":null,\"status\":null}\n",
      "1 | assistant: {\"type\":\"function_call\",\"call_id\":\"call_8GNP11VrQJsTBRW7xNUWffsI\",\"name\":\"get_current_weather\",\"arguments\":\"{\\\"location\\\":\\\"Boston, MA\\\",\\\"unit\\\":\\\"celsius\\\"}\"}\n",
      "0 | tool: {\"type\":\"function_call_output\",\"call_id\":\"call_8GNP11VrQJsTBRW7xNUWffsI\",\"output\":\"{\\\"weather\\\":\\\"Sunny\\\",\\\"temp_c\\\":22,\\\"location\\\":\\\"Boston, MA\\\",\\\"unit\\\":\\\"celsius\\\"}\"}\n",
      "0 | assistant: The current weather in Boston, MA is:\n",
      "\n",
      "- Condition: Sunny  \n",
      "- Temperature: 22Â°C  \n",
      "\n",
      "Let me know if you need anything else!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romanlutz\\AppData\\Local\\Temp\\ipykernel_57456\\3242724227.py:55: DeprecationWarning: MessagePiece.role getter is deprecated. Use api_role for comparisons. This property will be removed in 0.13.0.\n",
      "  print(f\"{idx} | {piece.role}: {piece.original_value}\")\n"
     ]
    }
   ],
   "source": [
    "from pyrit.models import Message, MessagePiece\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "\n",
    "async def get_current_weather(args):\n",
    "    return {\n",
    "        \"weather\": \"Sunny\",\n",
    "        \"temp_c\": 22,\n",
    "        \"location\": args[\"location\"],\n",
    "        \"unit\": args[\"unit\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# Responses API function tool schema (flat, no nested \"function\" key)\n",
    "function_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_current_weather\",\n",
    "    \"description\": \"Get the current weather in a given location\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\"type\": \"string\", \"description\": \"City and state\"},\n",
    "            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "        },\n",
    "        \"required\": [\"location\", \"unit\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "# Let the model auto-select tools\n",
    "target = OpenAIResponseTarget(\n",
    "    custom_functions={\"get_current_weather\": get_current_weather},\n",
    "    extra_body_parameters={\n",
    "        \"tools\": [function_tool],\n",
    "        \"tool_choice\": \"auto\",\n",
    "    },\n",
    "    httpx_client_kwargs={\"timeout\": 60.0},\n",
    ")\n",
    "\n",
    "# Build the user prompt\n",
    "message_piece = MessagePiece(\n",
    "    role=\"user\",\n",
    "    original_value=\"What is the weather in Boston in celsius? Use the get_current_weather function.\",\n",
    "    original_value_data_type=\"text\",\n",
    ")\n",
    "message = Message(message_pieces=[message_piece])\n",
    "\n",
    "response = await target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "for response_msg in response:\n",
    "    for idx, piece in enumerate(response_msg.message_pieces):\n",
    "        print(f\"{idx} | {piece.role}: {piece.original_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Using the Built-in Web Search Tool\n",
    "\n",
    "In this example, we use a built-in PyRIT helper function `web_search_tool()` to register a web search tool with OpenAI's Responses API. This allows the model to issue web search queries during a conversation to supplement its responses with fresh information.\n",
    "\n",
    "The tool is added to the `extra_body_parameters` passed into the `OpenAIResponseTarget`. As before, `tool_choice=\"auto\"` enables the model to decide when to invoke the tool.\n",
    "\n",
    "The user prompt asks for a recent positive news story â€” an open-ended question that may prompt the model to issue a web search tool call. PyRIT will automatically execute the tool and return the output to the model as part of the response.\n",
    "\n",
    "This example demonstrates how retrieval-augmented generation (RAG) can be enabled in PyRIT through OpenAI's Responses API and integrated tool schema.\n",
    "\n",
    "NOTE that web search is NOT supported through an Azure OpenAI endpoint, only through the OpenAI platform endpoint (i.e. api.openai.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | assistant: {\"type\":\"web_search_call\",\"id\":\"ws_0e658c491ae76624006999b4458cd88195b5ce5b1d4311e5f0\"}\n",
      "1 | assistant: A positive news story from today: An Indian teacher has been awarded $1 million for transforming slums into more than 800 vibrant classrooms, helping provide quality education to some of the countryâ€™s most underserved children and communities. This remarkable achievement was recognized with one of education's highest honors and showcases the power of dedication and community change [Only Good News Daily](https://www.onlygoodnewsdaily.com/).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romanlutz\\AppData\\Local\\Temp\\ipykernel_57456\\1088752442.py:31: DeprecationWarning: MessagePiece.role getter is deprecated. Use api_role for comparisons. This property will be removed in 0.13.0.\n",
      "  print(f\"{idx} | {piece.role}: {piece.original_value}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyrit.common.tool_configs import web_search_tool\n",
    "from pyrit.models import Message, MessagePiece\n",
    "from pyrit.prompt_target import OpenAIResponseTarget\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "# Note: web search is only supported on a limited set of models.\n",
    "target = OpenAIResponseTarget(\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_GPT41_RESPONSES_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_GPT41_RESPONSES_KEY\"),\n",
    "    model_name=os.getenv(\"AZURE_OPENAI_GPT41_RESPONSES_MODEL\"),\n",
    "    extra_body_parameters={\n",
    "        \"tools\": [web_search_tool()],\n",
    "        \"tool_choice\": \"auto\",\n",
    "    },\n",
    "    httpx_client_kwargs={\"timeout\": 60},\n",
    ")\n",
    "\n",
    "message_piece = MessagePiece(\n",
    "    role=\"user\", original_value=\"Briefly, what is one positive news story from today?\", original_value_data_type=\"text\"\n",
    ")\n",
    "message = Message(message_pieces=[message_piece])\n",
    "\n",
    "response = await target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "for response_msg in response:\n",
    "    for idx, piece in enumerate(response_msg.message_pieces):\n",
    "        print(f\"{idx} | {piece.role}: {piece.original_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Grammar-Constrained Generation\n",
    "\n",
    "OpenAI models also support constrained generation in the [Responses API](https://platform.openai.com/docs/guides/function-calling#context-free-grammars). This forces the LLM to produce output which conforms to the given grammar, which is useful when specific syntax is required in the output.\n",
    "\n",
    "In this example, we will define a simple Lark grammar which prevents the model from giving a correct answer to a simple question, and compare that to the unconstrained model.\n",
    "\n",
    "Note that as of October 2025, this is only supported by OpenAI (not Azure) on \"gpt-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\romanlutz\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\romanlutz\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unconstrained Response:\n",
      "0 | assistant: {\"id\":\"rs_0b3939d0f514d263006999b449cc3c8193985fe0f7ace8744a\",\"summary\":[],\"type\":\"reasoning\",\"content\":null,\"encrypted_content\":null,\"status\":null}\n",
      "1 | assistant: Rome.\n",
      "\n",
      "Constrained Response:\n",
      "0 | assistant: {\"id\":\"rs_03dbe2c775949fb6006999b44ed1c08190ac23b08a1bfa9668\",\"summary\":[],\"type\":\"reasoning\",\"content\":null,\"encrypted_content\":null,\"status\":null}\n",
      "1 | assistant: I think that it is Pisa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romanlutz\\AppData\\Local\\Temp\\ipykernel_57456\\138977321.py:51: DeprecationWarning: MessagePiece.role getter is deprecated. Use api_role for comparisons. This property will be removed in 0.13.0.\n",
      "  print(f\"{idx} | {piece.role}: {piece.original_value}\")\n",
      "C:\\Users\\romanlutz\\AppData\\Local\\Temp\\ipykernel_57456\\138977321.py:58: DeprecationWarning: MessagePiece.role getter is deprecated. Use api_role for comparisons. This property will be removed in 0.13.0.\n",
      "  print(f\"{idx} | {piece.role}: {piece.original_value}\")\n"
     ]
    }
   ],
   "source": [
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "message_piece = MessagePiece(\n",
    "    role=\"user\",\n",
    "    original_value=\"What is the capital of Italy?\",\n",
    "    original_value_data_type=\"text\",\n",
    ")\n",
    "message = Message(message_pieces=[message_piece])\n",
    "\n",
    "# Define a grammar that prevents \"Rome\" from being generated\n",
    "lark_grammar = r\"\"\"\n",
    "start: \"I think that it is \" SHORTTEXT\n",
    "SHORTTEXT: /[^RrOoMmEe]{1,8}/\n",
    "\"\"\"\n",
    "\n",
    "grammar_tool = {\n",
    "    \"type\": \"custom\",\n",
    "    \"name\": \"CitiesGrammar\",\n",
    "    \"description\": \"Constrains generation.\",\n",
    "    \"format\": {\n",
    "        \"type\": \"grammar\",\n",
    "        \"syntax\": \"lark\",\n",
    "        \"definition\": lark_grammar,\n",
    "    },\n",
    "}\n",
    "\n",
    "target = OpenAIResponseTarget(\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_GPT5_RESPONSES_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_GPT5_KEY\"),\n",
    "    model_name=os.getenv(\"AZURE_OPENAI_GPT5_MODEL\"),\n",
    "    extra_body_parameters={\"tools\": [grammar_tool], \"tool_choice\": \"required\"},\n",
    "    temperature=1.0,\n",
    ")\n",
    "\n",
    "unconstrained_target = OpenAIResponseTarget(\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_GPT5_RESPONSES_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_GPT5_KEY\"),\n",
    "    model_name=os.getenv(\"AZURE_OPENAI_GPT5_MODEL\"),\n",
    "    temperature=1.0,\n",
    ")\n",
    "\n",
    "unconstrained_result = await unconstrained_target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "result = await target.send_prompt_async(message=message)  # type: ignore\n",
    "\n",
    "print(\"Unconstrained Response:\")\n",
    "for response_msg in unconstrained_result:\n",
    "    for idx, piece in enumerate(response_msg.message_pieces):\n",
    "        print(f\"{idx} | {piece.role}: {piece.original_value}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Constrained Response:\")\n",
    "for response_msg in result:\n",
    "    for idx, piece in enumerate(response_msg.message_pieces):\n",
    "        print(f\"{idx} | {piece.role}: {piece.original_value}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
