{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ac463d",
   "metadata": {},
   "source": [
    "## AML Chat Targets\n",
    "\n",
    "This code shows how to use Azure Machine Learning (AML) managed online endpoints with PyRIT.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. **Deploy an AML-Managed Online Endpoint:** Confirm that an Azure Machine Learning managed online endpoint is\n",
    "     already deployed.\n",
    "\n",
    "1. **Obtain the API Key:**\n",
    "   - Navigate to the AML Studio.\n",
    "   - Go to the 'Endpoints' section.\n",
    "   - Retrieve the API key and endpoint URI from the 'Consume' tab\n",
    "   <br> <img src=\"../../../assets/aml_managed_online_endpoint_api_key.png\" alt=\"aml_managed_online_endpoint_api_key.png\" height=\"400\"/> <br>\n",
    "\n",
    "1. **Set the Environment Variable:**\n",
    "   - Go to 'Model ID' section under the 'Details' tab and click the link to find the model name at the top of the page (e.g., mistralai-Mistral-7B-Instruct-v01) \n",
    "   - Add the obtained API key to an environment variable named `{MODEL_NAME}_KEY` with all letters capitalized and dashes replaced with underscores\n",
    "     (e.g., `MISTRALAI_MISTRAL_7B_INSTRUCT_V01_KEY` or `PHI_3_MINI_4K_INSTRUCT_KEY`).\n",
    "   - Add the obtained endpoint URI to an environment variable named `{MODEL_NAME}_ENDPOINT` with all letters capitalized and dashes replaced with underscores\n",
    "     (e.g., `MISTRALAI_MISTRAL_7B_INSTRUCT_V01_ENDPOINT` or `PHI_3_MINI_4K_INSTRUCT_ENDPOINT`).\n",
    "\n",
    "### Create a AzureMLChatTarget\n",
    "\n",
    "After deploying a model and populating your env file, send prompts to the model using the `AzureMLChatTarget` class. Model parameters can be passed upon instantiation\n",
    "or set using the _set_model_parameters() function. `**param_kwargs` allows for the setting of other parameters not explicitly shown in the constructor. A general list of \n",
    "possible adjustable parameters can be found here: https://huggingface.co/docs/api-inference/tasks/text-generation but note that not all parameters may have an effect\n",
    "depending on the specific model. The parameters that can be set per model can usually be found in the 'Consume' tab when you click on your endpoint in AML Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__type__': 'AzureMLChatTarget', '__module__': 'pyrit.prompt_target.prompt_chat_target.azure_ml_chat_target'}: assistant: I am an artificial intelligence designed to assist with a wide range of tasks and provide information, answer questions, and engage in conversation on a variety of topics. I am powered by advanced machine learning algorithms that allow me to understand and respond to natural language inputs. I was developed by Mistral AI, a cutting-edge AI company based in Paris, France. Mistral AI is dedicated to creating intelligent systems that can understand, learn, and interact with humans in a natural and intuitive way. The company's mission is to make AI accessible and useful to everyone, and I am just one of the many tools and technologies that Mistral AI is developing to achieve this goal.\n"
     ]
    }
   ],
   "source": [
    "from pyrit.common import default_values\n",
    "from pyrit.orchestrator import PromptSendingOrchestrator\n",
    "from pyrit.prompt_target import AzureMLChatTarget\n",
    "\n",
    "default_values.load_default_env()\n",
    "\n",
    "# Defaults to \"mistralai-Mixtral-8x7B-Instruct-v01\"\n",
    "azure_ml_chat_target = AzureMLChatTarget()\n",
    "# Parameters such as temperature and repetition_penalty can be set using the _set_model_parameters() function. \n",
    "azure_ml_chat_target._set_model_parameters(temperature = 0.9, repetition_penalty=1.3)\n",
    "\n",
    "with PromptSendingOrchestrator(prompt_target=azure_ml_chat_target) as orchestrator:\n",
    "    response = await orchestrator.send_prompts_async(prompt_list=[\"Hello! Describe yourself and the company who developed you.\"])  # type: ignore\n",
    "    print(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6447ff",
   "metadata": {},
   "source": [
    "\n",
    "You can then use this cell anywhere you would use a `PromptTarget` object.\n",
    "For example, you can create a red teaming orchestrator and use this instead of the `AzureOpenAI` target and do the [Gandalf or Crucible Demos](./3_custom_targets.ipynb) but use this AML model.\n",
    "\n",
    "This is also shown in the [Red Teaming Orchestrator](../orchestrators/3_red_teaming_orchestrator.ipynb) documentation."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "pyrit-311",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
