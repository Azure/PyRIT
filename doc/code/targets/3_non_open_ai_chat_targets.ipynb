{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11fc9d2",
   "metadata": {},
   "source": [
    "# 3. AML Chat Targets\n",
    "\n",
    "This code shows how to use Azure Machine Learning (AML) managed online endpoints with PyRIT.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Deploy an AML-Managed Online Endpoint:** Confirm that an Azure Machine Learning managed online endpoint is\n",
    "     already deployed.\n",
    "\n",
    "1. **Obtain the API Key:**\n",
    "   - Navigate to the AML Studio.\n",
    "   - Go to the 'Endpoints' section.\n",
    "   - Retrieve the API key and endpoint URI from the 'Consume' tab\n",
    "   <br> <img src=\"../../../assets/aml_managed_online_endpoint_api_key.png\" alt=\"aml_managed_online_endpoint_api_key.png\" height=\"400\"/> <br>\n",
    "\n",
    "1. **Set the Environment Variable:**\n",
    "   - Add the obtained API key to an environment variable named `AZURE_ML_KEY`. This is the default API key when the target is instantiated.\n",
    "   - Add the obtained endpoint URI to an environment variable named `AZURE_ML_MANAGED_ENDPOINT`. This is the default endpoint URI when the target is instantiated.\n",
    "   - If you'd like, feel free to make additional API key and endpoint URI environment variables in your .env file for different deployed models (e.g. mistralai-Mixtral-8x7B-Instruct-v01,\n",
    "     Phi-3.5-MoE-instruct, Llama-3.2-3B-Instruct, etc.)\n",
    "     and pass them in as arguments to the `_set_env_configuration_vars` function to interact with those models.\n",
    "\n",
    "\n",
    "## Create a AzureMLChatTarget\n",
    "\n",
    "After deploying a model and populating your env file, send prompts to the model using the `AzureMLChatTarget` class. Model parameters can be passed upon instantiation\n",
    "or set using the _set_model_parameters() function. `**param_kwargs` allows for the setting of other parameters not explicitly shown in the constructor. A general list of\n",
    "possible adjustable parameters can be found here: https://huggingface.co/docs/api-inference/tasks/text-generation but note that not all parameters may have an effect\n",
    "depending on the specific model. The parameters that can be set per model can usually be found in the 'Consume' tab when you navigate to your endpoint in AML Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79367ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T21:57:46.050708Z",
     "iopub.status.busy": "2025-12-23T21:57:46.050470Z",
     "iopub.status.idle": "2025-12-23T21:58:03.858609Z",
     "shell.execute_reply": "2025-12-23T21:58:03.856549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\rlundeen\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\rlundeen\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\rlundeen\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\rlundeen\\.pyrit\\.env.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[34mðŸ”¹ Turn 1 - USER\u001b[0m\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[34m  Hello! Describe yourself and the company who developed you.\u001b[0m\n",
      "\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[1m\u001b[33mðŸ”¸ ASSISTANT\u001b[0m\n",
      "\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
      "\u001b[33m  Hello! I'm Phi, developed by Microsoft, a versatile digital assistant designed to help users with\u001b[0m\n",
      "\u001b[33m      a wide range of tasks, from answering questions to assisting with projects and research.\u001b[0m\n",
      "\u001b[33m      Microsoft aims to create Phi to enhance human ability, helping users accomplish more in their\u001b[0m\n",
      "\u001b[33m      everyday lives while supporting Microsoftâ€™s mission to empower every person and organization on\u001b[0m\n",
      "\u001b[33m      the planet to achieve more.\u001b[0m\n",
      "\n",
      "\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyrit.executor.attack import ConsoleAttackResultPrinter, PromptSendingAttack\n",
    "from pyrit.prompt_target import AzureMLChatTarget\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "# Defaults to endpoint and api_key pulled from the AZURE_ML_MANAGED_ENDPOINT and AZURE_ML_KEY environment variables\n",
    "azure_ml_chat_target = AzureMLChatTarget()\n",
    "\n",
    "# The environment variable args can be adjusted below as needed for your specific model.\n",
    "azure_ml_chat_target._set_env_configuration_vars(\n",
    "    endpoint_uri_environment_variable=\"AZURE_ML_MANAGED_ENDPOINT\", api_key_environment_variable=\"AZURE_ML_KEY\"\n",
    ")\n",
    "# Parameters such as temperature and repetition_penalty can be set using the _set_model_parameters() function.\n",
    "azure_ml_chat_target._set_model_parameters(temperature=0.9, repetition_penalty=1.3)\n",
    "\n",
    "attack = PromptSendingAttack(objective_target=azure_ml_chat_target)\n",
    "\n",
    "result = await attack.execute_async(objective=\"Hello! Describe yourself and the company who developed you.\")  # type: ignore\n",
    "await ConsoleAttackResultPrinter().print_conversation_async(result=result)  # type: ignore\n",
    "\n",
    "azure_ml_chat_target.dispose_db_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75326342",
   "metadata": {},
   "source": [
    "\n",
    "You can then use this cell anywhere you would use a `PromptTarget` object.\n",
    "For example, you can create a red teaming attack and use this instead of the `AzureOpenAI` target and do the [Gandalf or Crucible Demos](./2_custom_targets.ipynb) but use this AML model.\n",
    "\n",
    "This is also shown in the [Red Teaming Attack](../executor/attack/2_red_teaming_attack.ipynb) documentation."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (pyrit-dev)",
   "language": "python",
   "name": "pyrit-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
