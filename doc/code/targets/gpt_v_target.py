# %% [markdown]
# ## AzureOpenAIGPTVChatTarget
#
#
# This demo showcases the capabilities of `AzureOpenAIGPTVChatTarget` for generating text based on multimodal inputs, including both text and image input using `PromptSendingOrchestrator`. (This target has been largely replaced by GPT 4-o.) In this case, we're simply asking the GPT-V target to describe this picture:
#
# <img src="../../../assets/pyrit_architecture.png" />

# %%
from pyrit.common import default_values
import pathlib
from pyrit.common.path import HOME_PATH

from pyrit.prompt_target import AzureOpenAIGPTVChatTarget
from pyrit.prompt_normalizer.normalizer_request import NormalizerRequestPiece
from pyrit.prompt_normalizer.normalizer_request import NormalizerRequest
from pyrit.orchestrator import PromptSendingOrchestrator

default_values.load_default_env()

azure_openai_gptv_chat_target = AzureOpenAIGPTVChatTarget()

image_path = pathlib.Path(HOME_PATH) / "assets" / "pyrit_architecture.png"
data = [
    [
        {"prompt_text": "Describe this picture:", "prompt_data_type": "text"},
        {"prompt_text": str(image_path), "prompt_data_type": "image_path"},
    ],
    [{"prompt_text": "Tell me about something?", "prompt_data_type": "text"}],
    [{"prompt_text": str(image_path), "prompt_data_type": "image_path"}],
]


normalizer_requests = []

for piece_data in data:
    request_pieces = []

    for item in piece_data:
        prompt_text = item.get("prompt_text", "")  # type: ignore
        prompt_data_type = item.get("prompt_data_type", "")
        converters = []  # type: ignore
        request_piece = NormalizerRequestPiece(
            prompt_value=prompt_text, prompt_data_type=prompt_data_type, request_converters=converters  # type: ignore
        )
        request_pieces.append(request_piece)

    normalizer_request = NormalizerRequest(request_pieces)
    normalizer_requests.append(normalizer_request)


with PromptSendingOrchestrator(prompt_target=azure_openai_gptv_chat_target) as orchestrator:

    await orchestrator.send_normalizer_requests_async(prompt_request_list=normalizer_requests)  # type: ignore

    memory = orchestrator.get_memory()

    for entry in memory:
        print(entry)
