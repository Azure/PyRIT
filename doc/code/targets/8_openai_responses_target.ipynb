{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 8. OpenAI Responses Target\n",
    "\n",
    "In this demo, we show an example of the `OpenAIResponseTarget`. [Responses](https://platform.openai.com/docs/api-reference/responses) is a newer protocol than chat completions and provides additional functionality with a somewhat modified API. The allowed input types include text, image, web search, file search, functions, reasoning, and computer use.\n",
    "\n",
    "Before you begin, ensure you are set up with the correct version of PyRIT installed and have secrets configured as described [here](../../setup/populating_secrets.md).\n",
    "\n",
    "\n",
    "## OpenAI Configuration\n",
    "\n",
    "Like most targets, all `OpenAITarget`s need an `endpoint` and often also needs a `model` and a `key`. These can be passed into the constructor or configured with environment variables (or in .env).\n",
    "\n",
    "- endpoint: The API endpoint (`OPENAI_RESPONSES_ENDPOINT` environment variable). For OpenAI, these are just \"https://api.openai.com/v1/responses\".\n",
    "- auth: The API key for authentication (`OPENAI_RESPONSES_KEY` environment variable).\n",
    "- model_name: The model to use (`OPENAI_RESPONSES_MODEL` environment variable). For OpenAI, these are any available model name and are listed here: \"https://platform.openai.com/docs/models\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrit.common import IN_MEMORY, initialize_pyrit\n",
    "from pyrit.executor.attack import ConsoleAttackResultPrinter, PromptSendingAttack\n",
    "from pyrit.prompt_target import OpenAIResponseTarget\n",
    "\n",
    "initialize_pyrit(memory_db_type=IN_MEMORY)\n",
    "\n",
    "target = OpenAIResponseTarget()\n",
    "\n",
    "attack = PromptSendingAttack(objective_target=target)\n",
    "\n",
    "result = await attack.execute_async(objective=\"Tell me a joke\")  # type: ignore\n",
    "await ConsoleAttackResultPrinter().print_conversation_async(result=result)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Tool Use with Custom Functions\n",
    "\n",
    "In this example, we demonstrate how the OpenAI `Responses API` can be used to invoke a **custom-defined Python function** during a conversation. This is part of OpenAI’s support for \"function calling\", where the model decides to call a registered function, and the application executes it and passes the result back into the conversation loop.\n",
    "\n",
    "We define a simple tool called `get_current_weather`, which simulates weather information retrieval. A corresponding OpenAI tool schema describes the function name, parameters, and expected input format.\n",
    "\n",
    "The function is registered in the `custom_functions` argument of `OpenAIResponseTarget`. The `extra_body_parameters` include:\n",
    "\n",
    "- `tools`: the full OpenAI tool schema for `get_current_weather`.\n",
    "- `tool_choice: \"auto\"`: instructs the model to decide when to call the function.\n",
    "\n",
    "The user prompt explicitly asks the model to use the `get_current_weather` function. Once the model responds with a `function_call`, PyRIT executes the function, wraps the output, and the conversation continues until a final answer is produced.\n",
    "\n",
    "This showcases how agentic function execution works with PyRIT + OpenAI Responses API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | assistant: The current weather in Boston is Sunny with a temperature of 22°C.\n"
     ]
    }
   ],
   "source": [
    "from pyrit.common import IN_MEMORY, initialize_pyrit\n",
    "from pyrit.models import PromptRequestPiece, PromptRequestResponse\n",
    "from pyrit.prompt_target.openai.openai_response_target import OpenAIResponseTarget\n",
    "\n",
    "initialize_pyrit(memory_db_type=IN_MEMORY)\n",
    "\n",
    "\n",
    "async def get_current_weather(args):\n",
    "    return {\n",
    "        \"weather\": \"Sunny\",\n",
    "        \"temp_c\": 22,\n",
    "        \"location\": args[\"location\"],\n",
    "        \"unit\": args[\"unit\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# Responses API function tool schema (flat, no nested \"function\" key)\n",
    "function_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_current_weather\",\n",
    "    \"description\": \"Get the current weather in a given location\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\"type\": \"string\", \"description\": \"City and state\"},\n",
    "            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "        },\n",
    "        \"required\": [\"location\", \"unit\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "# Let the model auto-select tools\n",
    "target = OpenAIResponseTarget(\n",
    "    model_name=\"o4-mini\",\n",
    "    custom_functions={\"get_current_weather\": get_current_weather},\n",
    "    extra_body_parameters={\n",
    "        \"tools\": [function_tool],\n",
    "        \"tool_choice\": \"auto\",\n",
    "    },\n",
    "    httpx_client_kwargs={\"timeout\": 60.0},\n",
    "    api_version=None,  # using api.openai.com\n",
    ")\n",
    "\n",
    "# Build the user prompt\n",
    "prompt_piece = PromptRequestPiece(\n",
    "    role=\"user\",\n",
    "    original_value=\"What is the weather in Boston in celsius? Use the get_current_weather function.\",\n",
    "    original_value_data_type=\"text\",\n",
    ")\n",
    "prompt_request = PromptRequestResponse(request_pieces=[prompt_piece])\n",
    "\n",
    "response = await target.send_prompt_async(prompt_request=prompt_request) # type: ignore\n",
    "\n",
    "for idx, piece in enumerate(response.request_pieces):\n",
    "    print(f\"{idx} | {piece.role}: {piece.original_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Using the Built-in Web Search Tool\n",
    "\n",
    "In this example, we use a built-in PyRIT helper function `web_search_tool()` to register a web search tool with OpenAI's Responses API. This allows the model to issue web search queries during a conversation to supplement its responses with fresh information.\n",
    "\n",
    "The tool is added to the `extra_body_parameters` passed into the `OpenAIResponseTarget`. As before, `tool_choice=\"auto\"` enables the model to decide when to invoke the tool.\n",
    "\n",
    "The user prompt asks for a recent positive news story — an open-ended question that may prompt the model to issue a web search tool call. PyRIT will automatically execute the tool and return the output to the model as part of the response.\n",
    "\n",
    "This example demonstrates how retrieval-augmented generation (RAG) can be enabled in PyRIT through OpenAI's Responses API and integrated tool schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | assistant: {\"id\":\"ws_68b1812d8fe08193a0e62ea594b017d40f621171e76bbeaf\",\"type\":\"web_search_call\",\"status\":\"completed\",\"action\":{\"type\":\"search\",\"query\":\"positive good news stories today\"}}\n",
      "1 | assistant: Here are some positive news stories from August 29, 2025:\n",
      "\n",
      "**1. Dutch Cities Install Tiny Staircases to Save Cats**\n",
      "\n",
      "In Amsterdam and Amersfoort, a project is underway to install small staircases along canals, allowing cats who fall in to climb out safely. Funded by a €100,000 environment and biodiversity grant, over 500 cat-friendly escape routes are expected by year’s end. Judith Krom of Party for the Animals stated, \"A simple measure can prevent enormous animal suffering.\" ([podego.com](https://www.podego.com/insights/august-2025-good-news-ai-pfas-stories?utm_source=openai))\n",
      "\n",
      "**2. Gut Bacteria May Help Eliminate PFAS Chemicals**\n",
      "\n",
      "Scientists at the University of Cambridge discovered that specific gut bacteria can absorb and help eliminate PFAS, the \"forever chemicals\" linked to health risks. In lab studies, mice with humanized gut bacteria successfully excreted PFAS through their feces. Dr. Kiran Patil noted, \"Certain species of human gut bacteria have a remarkably high capacity to soak up PFAS.\" ([podego.com](https://www.podego.com/insights/august-2025-good-news-ai-pfas-stories?utm_source=openai))\n",
      "\n",
      "**3. New Bionic Knee Enhances Mobility for Amputees**\n",
      "\n",
      "A new bionic knee, developed over seven years, offers lower-leg amputees improved agility, comfort, and a sense of \"embodiment.\" The device integrates muscle function restoration, a titanium rod connected to the femur, and a robotic limb, resulting in better performance and reduced fatigue. Patients reported a greater feeling of the prosthetic being part of their body. ([dailykos.com](https://www.dailykos.com/stories/2025/8/26/2339419/-GNR-for-Tuesday-August-26-2025-Yup-there-s-good-news-galore?utm_source=openai))\n",
      "\n",
      "**4. Lavender Farming Boosts Economy in Kashmir**\n",
      "\n",
      "Farmers in Kashmir's Pulwama region have shifted from traditional apple farming to cultivating lavender, known as \"purple gold.\" This crop is cheaper to grow, pest-resistant, and yields tenfold profits. Supported by government initiatives like the Aroma Mission, lavender farming has become a cultural and economic boon, attracting young farmers and revitalizing the community. ([medium.com](https://medium.com/mind-yourself/good-news-friday-1st-august-2025-7ccce0dcc420?utm_source=openai))\n",
      "\n",
      "**5. 12-Year-Old Designs Solar-Powered Sleeping Bags for Homeless**\n",
      "\n",
      "A 12-year-old was named 'Girl of the Year' for designing solar-powered sleeping bags to aid homeless individuals. The invention retains heat and features a control circuit that conserves battery life by alternating between on/off states based on temperature readings. ([goodgoodgood.co](https://www.goodgoodgood.co/articles/good-news-this-week-august-23-2025?utm_source=openai))\n",
      "\n",
      "These stories highlight innovative solutions and compassionate initiatives making a positive impact globally. \n"
     ]
    }
   ],
   "source": [
    "from pyrit.common import IN_MEMORY, initialize_pyrit\n",
    "from pyrit.common.tool_configs import web_search_tool\n",
    "from pyrit.models import PromptRequestPiece, PromptRequestResponse\n",
    "from pyrit.prompt_target.openai.openai_response_target import OpenAIResponseTarget\n",
    "\n",
    "initialize_pyrit(memory_db_type=IN_MEMORY)\n",
    "\n",
    "target = OpenAIResponseTarget(\n",
    "    extra_body_parameters={\n",
    "        \"tools\": [web_search_tool()],\n",
    "        \"tool_choice\": \"auto\",\n",
    "    },\n",
    "    httpx_client_kwargs={\"timeout\": 60},\n",
    ")\n",
    "\n",
    "prompt_piece = PromptRequestPiece(\n",
    "    role=\"user\", original_value=\"What is a positive news story from today?\", original_value_data_type=\"text\"\n",
    ")\n",
    "prompt_request = PromptRequestResponse(request_pieces=[prompt_piece])\n",
    "\n",
    "response = await target.send_prompt_async(prompt_request=prompt_request) # type: ignore\n",
    "\n",
    "for idx, piece in enumerate(response.request_pieces):\n",
    "    print(f\"{idx} | {piece.role}: {piece.original_value}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
