{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d820ad5",
   "metadata": {},
   "source": [
    "## AzureOpenAIGPTVChatTarget\n",
    "\n",
    "\n",
    "This demo showcases the capabilities of `AzureOpenAIGPTVChatTarget` for generating text based on multimodal inputs, including both text and image input using `PromptSendingOrchestrator`. (This target has been largely replaced by GPT 4-o.) In this case, we're simply asking the GPT-V target to describe this picture:\n",
    "\n",
    "<img src=\"../../../assets/pyrit_architecture.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8d32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File does not exist: /usr/local/python/3.12.1/lib/python3.12/site-packages/assets/pyrit_architecture.png",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m     prompt_data_type \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_data_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m     converters \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     request_piece \u001b[38;5;241m=\u001b[39m \u001b[43mNormalizerRequestPiece\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_data_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_data_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     request_pieces\u001b[38;5;241m.\u001b[39mappend(request_piece)\n\u001b[1;32m     39\u001b[0m normalizer_request \u001b[38;5;241m=\u001b[39m NormalizerRequest(request_pieces)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pyrit/prompt_normalizer/normalizer_request.py:44\u001b[0m, in \u001b[0;36mNormalizerRequestPiece.__init__\u001b[0;34m(self, request_converters, prompt_value, prompt_data_type, metadata)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_data_type \u001b[38;5;241m=\u001b[39m prompt_data_type\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pyrit/prompt_normalizer/normalizer_request.py:62\u001b[0m, in \u001b[0;36mNormalizerRequestPiece.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_converters must be a PromptConverter List\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# this validates the media exists, if needed\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mdata_serializer_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_data_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pyrit/models/data_type_serializer.py:22\u001b[0m, in \u001b[0;36mdata_serializer_factory\u001b[0;34m(data_type, value, extension)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TextDataTypeSerializer(prompt_text\u001b[38;5;241m=\u001b[39mvalue)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m data_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mImagePathDataTypeSerializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m data_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_path\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AudioPathDataTypeSerializer(prompt_text\u001b[38;5;241m=\u001b[39mvalue)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pyrit/models/data_type_serializer.py:205\u001b[0m, in \u001b[0;36mImagePathDataTypeSerializer.__init__\u001b[0;34m(self, prompt_text, extension)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m prompt_text\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue):\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File does not exist: /usr/local/python/3.12.1/lib/python3.12/site-packages/assets/pyrit_architecture.png"
     ]
    }
   ],
   "source": [
    "from pyrit.common import default_values\n",
    "import pathlib\n",
    "from pyrit.common.path import HOME_PATH\n",
    "\n",
    "from pyrit.prompt_target import AzureOpenAIGPTVChatTarget\n",
    "from pyrit.prompt_normalizer.normalizer_request import NormalizerRequestPiece\n",
    "from pyrit.prompt_normalizer.normalizer_request import NormalizerRequest\n",
    "from pyrit.orchestrator import PromptSendingOrchestrator\n",
    "\n",
    "default_values.load_default_env()\n",
    "\n",
    "azure_openai_gptv_chat_target = AzureOpenAIGPTVChatTarget()\n",
    "\n",
    "image_path = pathlib.Path(HOME_PATH) / \"assets\" / \"pyrit_architecture.png\"\n",
    "data = [\n",
    "    [\n",
    "        {\"prompt_text\": \"Describe this picture:\", \"prompt_data_type\": \"text\"},\n",
    "        {\"prompt_text\": str(image_path), \"prompt_data_type\": \"image_path\"},\n",
    "    ],\n",
    "    [{\"prompt_text\": \"Tell me about something?\", \"prompt_data_type\": \"text\"}],\n",
    "    [{\"prompt_text\": str(image_path), \"prompt_data_type\": \"image_path\"}],\n",
    "]\n",
    "\n",
    "\n",
    "normalizer_requests = []\n",
    "\n",
    "for piece_data in data:\n",
    "    request_pieces = []\n",
    "\n",
    "    for item in piece_data:\n",
    "        prompt_text = item.get(\"prompt_text\", \"\")  # type: ignore\n",
    "        prompt_data_type = item.get(\"prompt_data_type\", \"\")\n",
    "        converters = []  # type: ignore\n",
    "        request_piece = NormalizerRequestPiece(\n",
    "            prompt_value=prompt_text, prompt_data_type=prompt_data_type, request_converters=converters  # type: ignore\n",
    "        )\n",
    "        request_pieces.append(request_piece)\n",
    "\n",
    "    normalizer_request = NormalizerRequest(request_pieces)\n",
    "    normalizer_requests.append(normalizer_request)\n",
    "\n",
    "\n",
    "with PromptSendingOrchestrator(prompt_target=azure_openai_gptv_chat_target) as orchestrator:\n",
    "\n",
    "    await orchestrator.send_normalizer_requests_async(prompt_request_list=normalizer_requests)  # type: ignore\n",
    "\n",
    "    memory = orchestrator.get_memory()\n",
    "\n",
    "    for entry in memory:\n",
    "        print(entry)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "pyrit-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
