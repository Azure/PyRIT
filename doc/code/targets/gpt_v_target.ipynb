{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI GPT-V Target Demo\n",
    "This notebook demonstrates how to use the Azure OpenAI GPT-V target to accept multimodal input (text+image) and generate text output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "\n",
    "from pyrit.models import PromptRequestPiece, PromptRequestResponse\n",
    "from pyrit.prompt_target import AzureOpenAIGPTVChatTarget\n",
    "from pyrit.common import default_values\n",
    "import pathlib\n",
    "from pyrit.common.path import HOME_PATH\n",
    "import uuid\n",
    "\n",
    "default_values.load_default_env()\n",
    "test_conversation_id = str(uuid.uuid4())\n",
    "\n",
    "# use the image from our docs\n",
    "image_path = pathlib.Path(HOME_PATH) / \"assets\" / \"pyrit_architecture.png\"\n",
    "\n",
    "request_pieces = [\n",
    "PromptRequestPiece(\n",
    "    role=\"user\",\n",
    "    conversation_id=test_conversation_id,\n",
    "    original_prompt_text=\"Describe this picture:\",\n",
    "    original_prompt_data_type=\"text\",\n",
    "    converted_prompt_data_type=\"text\"\n",
    "), \n",
    "PromptRequestPiece(\n",
    "    role=\"user\",\n",
    "    conversation_id=test_conversation_id,\n",
    "    original_prompt_text=str(image_path),\n",
    "    original_prompt_data_type=\"image_path\",\n",
    "    converted_prompt_data_type=\"image_path\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_request_response = PromptRequestResponse(request_pieces=request_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: assistant: This picture shows a table that outlines the components of PyRIT. There are five main categories: Interface, Datasets, Scoring Engine, Attack Strategy, and Memory. Under each category are subcategories for implementation. For example, under 'Interface,' the implementations listed are local (using a local model) and remote (using an API or web app). The other categories also have specific implementations listed as bullet points. The image may be part of a technical manual or software documentation.\n"
     ]
    }
   ],
   "source": [
    "with AzureOpenAIGPTVChatTarget() as azure_openai_chat_target:\n",
    "    resp = await azure_openai_chat_target.send_prompt_async(prompt_request=prompt_request_response) # type: ignore\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyrit-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
