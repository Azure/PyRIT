{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI GPT-V Target Demo\n",
    "This notebook demonstrates how to use the Azure OpenAI GPT-V target to accept multimodal input (text+image) and generate text output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "\n",
    "from pyrit.models import PromptRequestPiece, PromptRequestResponse\n",
    "from pyrit.prompt_target import AzureOpenAIGPTVChatTarget\n",
    "from pyrit.common import default_values\n",
    "import pathlib\n",
    "from pyrit.common.path import HOME_PATH\n",
    "import uuid\n",
    "\n",
    "default_values.load_default_env()\n",
    "test_conversation_id = str(uuid.uuid4())\n",
    "\n",
    "# use the image from our docs\n",
    "image_path = pathlib.Path(HOME_PATH) / \"assets\" / \"pyrit_architecture.png\"\n",
    "\n",
    "request_pieces = [\n",
    "PromptRequestPiece(\n",
    "    role=\"user\",\n",
    "    conversation_id=test_conversation_id,\n",
    "    original_prompt_text=\"Describe this picture:\",\n",
    "    original_prompt_data_type=\"text\",\n",
    "    converted_prompt_data_type=\"text\"\n",
    "), \n",
    "PromptRequestPiece(\n",
    "    role=\"user\",\n",
    "    conversation_id=test_conversation_id,\n",
    "    original_prompt_text=str(image_path),\n",
    "    original_prompt_data_type=\"image_path\",\n",
    "    converted_prompt_data_type=\"image_path\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_request_response = PromptRequestResponse(request_pieces=request_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: assistant: This picture is a list of components for PyRIT, with two columns labeled \"Interface\" and \"Implementation.\" There are several categories listed under Interface: Target, Datasets, Scoring Engine, Attack Strategy, and Memory. Each category has a corresponding implementation listed on the right side.\n",
      "\n",
      "For Target, there is a Local option which includes local models like ONNX, and a Remote option that involves using an API or web app.\n",
      "\n",
      "Datasets can be either Static (prompts) or Dynamic (prompt templates).\n",
      "\n",
      "The Scoring Engine implementation is PyRIT Itself: Self Evaluation in addition to using APIs from existing content classifiers.\n",
      "\n",
      "Attack Strategy can be either Single Turn with static prompts or Multi Turn with multiple conversations using prompt templates.\n",
      "\n",
      "Memory includes Storage options like JSON and Database as well as Utils for conversation, retrieval and storage, memory sharing, and data analysis.\n"
     ]
    }
   ],
   "source": [
    "with AzureOpenAIGPTVChatTarget() as azure_openai_chat_target:\n",
    "    resp = await azure_openai_chat_target.send_prompt_async(prompt_request=prompt_request_response) # type: ignore\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyrit-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
