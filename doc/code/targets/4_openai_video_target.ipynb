{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5dec53b",
   "metadata": {},
   "source": [
    "# 4. OpenAI Video Target\n",
    "\n",
    "`OpenAIVideoTarget` supports three modes:\n",
    "- **Text-to-video**: Generate a video from a text prompt.\n",
    "- **Remix**: Create a variation of an existing video (using `video_id` from a prior generation).\n",
    "- **Text+Image-to-video**: Use an image as the first frame of the generated video.\n",
    "\n",
    "Note that the video scorer requires `opencv`, which is not a default PyRIT dependency. You need to install it manually or using `pip install pyrit[opencv]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81cc52",
   "metadata": {},
   "source": [
    "## Text-to-Video\n",
    "\n",
    "This example shows the simplest mode: generating video from text prompts, with scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrit.executor.attack import (\n",
    "    AttackExecutor,\n",
    "    AttackScoringConfig,\n",
    "    ConsoleAttackResultPrinter,\n",
    "    PromptSendingAttack,\n",
    ")\n",
    "from pyrit.prompt_target import OpenAIChatTarget, OpenAIVideoTarget\n",
    "from pyrit.score import (\n",
    "    AzureContentFilterScorer,\n",
    "    SelfAskTrueFalseScorer,\n",
    "    TrueFalseQuestion,\n",
    "    VideoFloatScaleScorer,\n",
    "    VideoTrueFalseScorer,\n",
    ")\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "video_target = OpenAIVideoTarget()\n",
    "objective_scorer = SelfAskTrueFalseScorer(\n",
    "    chat_target=OpenAIChatTarget(),\n",
    "    true_false_question=TrueFalseQuestion(true_description=\"A raccoon dressed as a pirate is actively eating a pastry\"),\n",
    ")\n",
    "\n",
    "video_scorer = VideoTrueFalseScorer(\n",
    "    image_capable_scorer=objective_scorer,\n",
    "    num_sampled_frames=10,\n",
    ")\n",
    "\n",
    "attack = PromptSendingAttack(\n",
    "    objective_target=video_target,\n",
    "    attack_scoring_config=AttackScoringConfig(\n",
    "        objective_scorer=video_scorer,\n",
    "        auxiliary_scorers=[VideoFloatScaleScorer(image_capable_scorer=AzureContentFilterScorer())],\n",
    "    ),\n",
    ")\n",
    "\n",
    "objectives = [\n",
    "    \"Video of a raccoon pirate eating flan at a cafe in Spain\",\n",
    "    \"Video of a raccoon pirate eating a croissant at a cafe in France\",\n",
    "]\n",
    "\n",
    "results = await AttackExecutor().execute_attack_async(  # type: ignore\n",
    "    attack=attack,\n",
    "    objectives=objectives,\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    await ConsoleAttackResultPrinter().print_result_async(result=result, include_auxiliary_scores=True)  # type: ignore\n",
    "\n",
    "# Capture video_id from the first result for use in the remix section below\n",
    "video_id = results[0].last_response.prompt_metadata[\"video_id\"]\n",
    "print(f\"Video ID for remix: {video_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42be24c",
   "metadata": {},
   "source": [
    "## Remix (Video Variation)\n",
    "\n",
    "Remix creates a variation of an existing video. After any successful generation, the response\n",
    "includes a `video_id` in `prompt_metadata`. Pass this back via `prompt_metadata={\"video_id\": \"<id>\"}` to remix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ae002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrit.models import Message, MessagePiece\n",
    "\n",
    "# Remix using the video_id captured from the text-to-video section above\n",
    "remix_piece = MessagePiece(\n",
    "    role=\"user\",\n",
    "    original_value=\"Make it a watercolor painting style\",\n",
    "    prompt_metadata={\"video_id\": video_id},\n",
    ")\n",
    "remix_result = await video_target.send_prompt_async(message=Message([remix_piece]))  # type: ignore\n",
    "print(f\"Remixed video: {remix_result[0].message_pieces[0].converted_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da232bc7",
   "metadata": {},
   "source": [
    "## Text+Image-to-Video\n",
    "\n",
    "Use an image as the first frame of the generated video. The input image dimensions must match\n",
    "the video resolution (e.g. 1280x720). Pass both a text piece and an `image_path` piece in the same message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47280280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Create a simple test image matching the video resolution (1280x720)\n",
    "from PIL import Image\n",
    "\n",
    "from pyrit.common.path import HOME_PATH\n",
    "\n",
    "sample_image = HOME_PATH / \"assets\" / \"pyrit_architecture.png\"\n",
    "resized = Image.open(sample_image).resize((1280, 720)).convert(\"RGB\")\n",
    "\n",
    "import tempfile\n",
    "\n",
    "tmp = tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False)\n",
    "resized.save(tmp, format=\"JPEG\")\n",
    "tmp.close()\n",
    "image_path = tmp.name\n",
    "\n",
    "# Send text + image to the video target\n",
    "i2v_target = OpenAIVideoTarget()\n",
    "conversation_id = str(uuid.uuid4())\n",
    "\n",
    "text_piece = MessagePiece(\n",
    "    role=\"user\",\n",
    "    original_value=\"Animate this image with gentle camera motion\",\n",
    "    conversation_id=conversation_id,\n",
    ")\n",
    "image_piece = MessagePiece(\n",
    "    role=\"user\",\n",
    "    original_value=image_path,\n",
    "    converted_value_data_type=\"image_path\",\n",
    "    conversation_id=conversation_id,\n",
    ")\n",
    "result = await i2v_target.send_prompt_async(message=Message([text_piece, image_piece]))  # type: ignore\n",
    "print(f\"Text+Image-to-video result: {result[0].message_pieces[0].converted_value}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
