{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Why Instance Registries?\n",
    "\n",
    "Some components need configuration that can't easily be passed at instantiation time. For example, scorers often need:\n",
    "- A configured `chat_target` for LLM-based scoring\n",
    "- Specific prompt templates\n",
    "- Other dependencies\n",
    "\n",
    "Instance registries let initializers register fully-configured instances that are ready to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Listing Available Instances\n",
    "\n",
    "Use `get_names()` to see registered instances, or `list_metadata()` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\rlundeen\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\rlundeen\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\rlundeen\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\rlundeen\\.pyrit\\.env.local\n",
      "Registered scorers: ['self_ask_refusal_d9007ba2']\n"
     ]
    }
   ],
   "source": [
    "from pyrit.prompt_target import OpenAIChatTarget\n",
    "from pyrit.registry import ScorerRegistry\n",
    "from pyrit.score import SelfAskRefusalScorer\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "# Get the registry singleton\n",
    "registry = ScorerRegistry.get_registry_singleton()\n",
    "\n",
    "# Register a scorer instance for demonstration\n",
    "chat_target = OpenAIChatTarget()\n",
    "refusal_scorer = SelfAskRefusalScorer(chat_target=chat_target)\n",
    "registry.register_instance(refusal_scorer)\n",
    "\n",
    "# List what's available\n",
    "names = registry.get_names()\n",
    "print(f\"Registered scorers: {names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Getting an Instance\n",
    "\n",
    "Use `get()` to retrieve a pre-configured instance by name. The instance is ready to use immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved scorer: <pyrit.score.true_false.self_ask_refusal_scorer.SelfAskRefusalScorer object at 0x0000026BFBE69A90>\n",
      "Scorer type: SelfAskRefusalScorer\n"
     ]
    }
   ],
   "source": [
    "# Get the first registered scorer\n",
    "if names:\n",
    "    scorer_name = names[0]\n",
    "    scorer = registry.get(scorer_name)\n",
    "    print(f\"Retrieved scorer: {scorer}\")\n",
    "    print(f\"Scorer type: {type(scorer).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Inspecting Metadata\n",
    "\n",
    "Scorer metadata includes the scorer type and identifier for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "self_ask_refusal_d9007ba2:\n",
      "  Class: SelfAskRefusalScorer\n",
      "  Type: true_false\n",
      "  Description: A self-ask scorer that detects refusal in AI responses. This...\n",
      "\n",
      "\u001b[1m  ðŸ“Š Scorer Information\u001b[0m\n",
      "\u001b[37m    â–¸ Scorer Identifier\u001b[0m\n",
      "\u001b[36m      â€¢ Scorer Type: SelfAskRefusalScorer\u001b[0m\n",
      "\u001b[36m      â€¢ Target Model: gpt-40\u001b[0m\n",
      "\u001b[36m      â€¢ Temperature: None\u001b[0m\n",
      "\u001b[36m      â€¢ Score Aggregator: OR_\u001b[0m\n",
      "\n",
      "\u001b[37m    â–¸ Performance Metrics\u001b[0m\n",
      "\u001b[33m      Official evaluation has not been run yet for this specific configuration\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyrit.score import ConsoleScorerPrinter\n",
    "\n",
    "# Get metadata for all registered scorers\n",
    "metadata = registry.list_metadata()\n",
    "for item in metadata:\n",
    "    print(f\"\\n{item.name}:\")\n",
    "    print(f\"  Class: {item.class_name}\")\n",
    "    print(f\"  Type: {item.scorer_type}\")\n",
    "    print(f\"  Description: {item.description[:60]}...\")\n",
    "\n",
    "    ConsoleScorerPrinter().print_objective_scorer(scorer_identifier=item.scorer_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Use `list_metadata()` with `include_filters` and `exclude_filters` dictionaries to filter scorers by any metadata property. `include_filters` requires ALL criteria to match (AND logic). `exclude_filters` excludes items matching ANY criteria. Filters use exact match for simple types and membership check for list types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True/False scorers: ['self_ask_refusal_d9007ba2']\n",
      "Refusal scorers: ['self_ask_refusal_d9007ba2']\n",
      "True/False refusal scorers: ['self_ask_refusal_d9007ba2']\n"
     ]
    }
   ],
   "source": [
    "# Filter by scorer_type (based on isinstance check against TrueFalseScorer/FloatScaleScorer)\n",
    "true_false_scorers = registry.list_metadata(include_filters={\"scorer_type\": \"true_false\"})\n",
    "print(f\"True/False scorers: {[m.name for m in true_false_scorers]}\")\n",
    "\n",
    "# Filter by class_name\n",
    "refusal_scorers = registry.list_metadata(include_filters={\"class_name\": \"SelfAskRefusalScorer\"})\n",
    "print(f\"Refusal scorers: {[m.name for m in refusal_scorers]}\")\n",
    "\n",
    "# Combine multiple filters (AND logic)\n",
    "specific_scorers = registry.list_metadata(\n",
    "    include_filters={\"scorer_type\": \"true_false\", \"class_name\": \"SelfAskRefusalScorer\"}\n",
    ")\n",
    "print(f\"True/False refusal scorers: {[m.name for m in specific_scorers]}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
