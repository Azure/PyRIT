{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d623d73a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# HuggingFace Chat Target Testing\n",
    "\n",
    "This notebook demonstrates the process of testing the HuggingFace Chat Target using various prompts.\n",
    "The target model will be loaded and interacted with using different prompts to examine its responses.\n",
    "The goal is to test the model's ability to handle various inputs and generate appropriate and safe outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ce3397",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Import necessary modules and classes\n",
    "from pyrit.prompt_target import HuggingFaceChatTarget  \n",
    "from pyrit.orchestrator import PromptSendingOrchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd6c2f",
   "metadata": {},
   "source": [
    "## Initialize the HuggingFace Chat Target\n",
    "\n",
    "Here, we initialize the `HuggingFaceChatTarget` with the desired model ID. We will also configure whether to use CUDA for GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d20d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = HuggingFaceChatTarget(\n",
    "    model_id=\"microsoft/Phi-3-mini-4k-instruct\",  # Use the desired model ID\n",
    "    use_cuda=False,  # Set this to True if you want to use CUDA and have GPU support\n",
    "    tensor_format=\"pt\",\n",
    "    verbose=False,\n",
    "    max_new_tokens=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize PromptSendingOrchestrator with HuggingFaceChatTarget\n",
    "orchestrator = PromptSendingOrchestrator(\n",
    "    prompt_target=target,  # Use HuggingFaceChatTarget as the prompt target\n",
    "    verbose=False  # Enable verbose logging for debugging\n",
    ")\n",
    "\n",
    "# Use the first few examples (adjust the range as needed)\n",
    "prompt_list = [\"What is 3*3?\", \"What is 4*4?\", \"What is 5*5?\", \"What is 6*6?\", \"What is 7*7?\"]\n",
    "\n",
    "# Send prompts using the orchestrator\n",
    "responses = await orchestrator.send_prompts_async(prompt_list=prompt_list)\n",
    "\n",
    "# Print the conversations and scoring results\n",
    "orchestrator.print_conversations()  # Use built-in method to display conversations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_target = HuggingFaceChatTarget(\n",
    "    model_id=\"HuggingFaceTB/SmolLM-135M-Instruct\",  # Use the desired model ID\n",
    "    use_cuda=False,  # Set this to True if you want to use CUDA and have GPU support\n",
    "    tensor_format=\"pt\",\n",
    "    verbose=False,\n",
    "    max_new_tokens=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize PromptSendingOrchestrator with HuggingFaceChatTarget\n",
    "orchestrator = PromptSendingOrchestrator(\n",
    "    prompt_target=another_target,  # Use HuggingFaceChatTarget as the prompt target\n",
    "    verbose=False  # Enable verbose logging for debugging\n",
    ")\n",
    "\n",
    "# Use the first few examples (adjust the range as needed)\n",
    "prompt_list = [\"What is 3*3?\", \"What is 4*4?\", \"What is 5*5?\", \"What is 6*6?\", \"What is 7*7?\"]\n",
    "\n",
    "# Send prompts using the orchestrator\n",
    "responses = await orchestrator.send_prompts_async(prompt_list=prompt_list)\n",
    "\n",
    "# Print the conversations and scoring results\n",
    "orchestrator.print_conversations()  # Use built-in method to display conversations"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
