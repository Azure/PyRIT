{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad25bc8",
   "metadata": {},
   "source": [
    "# 9. Printing Scorer Information\n",
    "\n",
    "The `ConsoleScorerPrinter` displays scorer details and cached evaluation metrics from the registry.\n",
    "It works with `ScorerIdentifier` objects, which can be obtained from any scorer instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44096a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found default environment files: ['C:\\\\Users\\\\rlundeen\\\\.pyrit\\\\.env', 'C:\\\\Users\\\\rlundeen\\\\.pyrit\\\\.env.local']\n",
      "Loaded environment file: C:\\Users\\rlundeen\\.pyrit\\.env\n",
      "Loaded environment file: C:\\Users\\rlundeen\\.pyrit\\.env.local\n",
      "\n",
      "\u001b[1m  ðŸ“Š Scorer Information\u001b[0m\n",
      "\u001b[37m    â–¸ Scorer Identifier\u001b[0m\n",
      "\u001b[36m      â€¢ Scorer Type: TrueFalseInverterScorer\u001b[0m\n",
      "\u001b[36m      â€¢ Score Aggregator: OR_\u001b[0m\n",
      "\u001b[36m        â””â”€ Composite of 1 scorer(s):\u001b[0m\n",
      "\u001b[36m            â€¢ Scorer Type: SelfAskRefusalScorer\u001b[0m\n",
      "\u001b[36m            â€¢ Target Model: gpt-4o-japan-nilfilter\u001b[0m\n",
      "\u001b[36m            â€¢ Temperature: None\u001b[0m\n",
      "\u001b[36m            â€¢ Score Aggregator: OR_\u001b[0m\n",
      "\n",
      "\u001b[37m    â–¸ Performance Metrics\u001b[0m\n",
      "\u001b[36m      â€¢ Accuracy: 82.43%\u001b[0m\n",
      "\u001b[36m      â€¢ Accuracy Std Error: Â±0.0313\u001b[0m\n",
      "\u001b[36m      â€¢ F1 Score: 0.8395\u001b[0m\n",
      "\u001b[36m      â€¢ Precision: 0.7727\u001b[0m\n",
      "\u001b[36m      â€¢ Recall: 0.9189\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyrit.prompt_target import OpenAIChatTarget\n",
    "from pyrit.score import SelfAskRefusalScorer, TrueFalseInverterScorer\n",
    "from pyrit.score.printer import ConsoleScorerPrinter\n",
    "from pyrit.setup import initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=\"InMemory\")\n",
    "\n",
    "# Create an objective scorer\n",
    "objective_scorer = TrueFalseInverterScorer(\n",
    "    scorer=SelfAskRefusalScorer(\n",
    "        chat_target=OpenAIChatTarget(\n",
    "            endpoint=os.environ.get(\"AZURE_OPENAI_GPT4O_ENDPOINT\"),\n",
    "            api_key=os.environ.get(\"AZURE_OPENAI_GPT4O_KEY\"),\n",
    "            model_name=os.environ.get(\"AZURE_OPENAI_GPT4O_MODEL\"),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Print scorer info and metrics\n",
    "printer = ConsoleScorerPrinter()\n",
    "printer.print_objective_scorer(objective_scorer.scorer_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e1667",
   "metadata": {},
   "source": [
    "## Printing Harm Scorer Metrics\n",
    "\n",
    "For harm scorers, pass the `harm_category` to look up the correct metrics file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb8734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m  ðŸ“Š Scorer Information\u001b[0m\n",
      "\u001b[37m    â–¸ Scorer Identifier\u001b[0m\n",
      "\u001b[36m      â€¢ Scorer Type: SelfAskLikertScorer\u001b[0m\n",
      "\u001b[36m      â€¢ Target Model: gpt-4o-japan-nilfilter\u001b[0m\n",
      "\u001b[36m      â€¢ Temperature: None\u001b[0m\n",
      "\n",
      "\u001b[37m    â–¸ Performance Metrics\u001b[0m\n",
      "\u001b[36m      â€¢ Mean Absolute Error: 0.1685\u001b[0m\n",
      "\u001b[36m      â€¢ MAE Std Error: Â±0.0307\u001b[0m\n",
      "\u001b[36m      â€¢ Krippendorff Alpha (Combined): 0.8492\u001b[0m\n",
      "\u001b[36m      â€¢ Krippendorff Alpha (Model): 0.9527\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyrit.score import SelfAskLikertScorer, LikertScalePaths\n",
    "\n",
    "# Create a harm scorer\n",
    "harm_scorer = SelfAskLikertScorer(\n",
    "    chat_target=OpenAIChatTarget(\n",
    "        endpoint=os.environ.get(\"AZURE_OPENAI_GPT4O_ENDPOINT\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_GPT4O_KEY\"),\n",
    "        model_name=os.environ.get(\"AZURE_OPENAI_GPT4O_MODEL\"),\n",
    "    ),\n",
    "    likert_scale=LikertScalePaths.HATE_SPEECH_SCALE,\n",
    ")\n",
    "\n",
    "# Print harm scorer info with category for metrics lookup\n",
    "printer.print_harm_scorer(harm_scorer.scorer_identifier, harm_category=\"hate_speech\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyrit (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
