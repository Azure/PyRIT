{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Float Scale Scoring using Azure Content Safety API\n",
    "\n",
    "The Azure Content Safety API is one of our most reliable scorers for detecting harms. Although it isn't very flexible, it's extremely fast and reliable and can be used to score images or text.\n",
    "\n",
    "In order to use this API, you need to configure a few environment variables:\n",
    "\n",
    "- AZURE_CONTENT_SAFETY_API_ENDPOINT: The endpoint for the Azure Content Safety API\n",
    "- AZURE_CONTENT_SAFETY_API_KEY: The API key for the Azure Content Safety API (if not using Entra Auth)\n",
    "\n",
    "As an alternative to key-based authentication, you can use Entra ID (identity-based) authentication.\n",
    "Use get_azure_token_provider() from pyrit.auth.azure_auth and pass it as the api_key parameter.\n",
    "Example:\n",
    "from pyrit.auth.azure_auth import get_azure_token_provider\n",
    "api_key = get_azure_token_provider(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "Note that this api returns a value between 0 and 7. This is different from likert scales, which return a value between 1 and 5. Because both are `float_scale` scores, these values are all normalized to floating point values between 0.0 and 1.0 and can be directly compared. This is sometimes interesting as an operator e.g. if there are scenarios where a `SelfAskLikertScorer` and `AzureContentFilterScorer` produce very different values.\n",
    "\n",
    "Before you begin, ensure you are setup with the correct version of PyRIT installed and have secrets configured as described [here](../../setup/populating_secrets.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureContentFilterScorer: Hate: 0.2857142857142857 {'azure_severity': 2}\n",
      "AzureContentFilterScorer: SelfHarm: 0.0 {'azure_severity': 0}\n",
      "AzureContentFilterScorer: Sexual: 0.0 {'azure_severity': 0}\n",
      "AzureContentFilterScorer: Violence: 0.0 {'azure_severity': 0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyrit.memory import CentralMemory\n",
    "from pyrit.models import Message, MessagePiece\n",
    "from pyrit.score.float_scale.azure_content_filter_scorer import AzureContentFilterScorer\n",
    "from pyrit.setup import IN_MEMORY, initialize_pyrit_async\n",
    "\n",
    "await initialize_pyrit_async(memory_db_type=IN_MEMORY)  # type: ignore\n",
    "\n",
    "\n",
    "# Set up the Azure Content Filter\n",
    "azure_content_filter = AzureContentFilterScorer(\n",
    "    api_key=os.environ.get(\"AZURE_CONTENT_SAFETY_API_KEY\"),\n",
    "    endpoint=os.environ.get(\"AZURE_CONTENT_SAFETY_API_ENDPOINT\"),\n",
    ")\n",
    "# For Entra ID authentication:\n",
    "# from pyrit.auth import get_azure_token_provider\n",
    "# endpoint = os.environ.get(\"AZURE_CONTENT_SAFETY_API_ENDPOINT\")\n",
    "# azure_content_filter = AzureContentFilterScorer(\n",
    "#     api_key=get_azure_token_provider(\"https://cognitiveservices.azure.com/.default\"),\n",
    "#     endpoint=endpoint,\n",
    "# )\n",
    "\n",
    "response = Message(\n",
    "    message_pieces=[\n",
    "        MessagePiece(\n",
    "            role=\"assistant\",\n",
    "            original_value_data_type=\"text\",\n",
    "            original_value=\"I hate you.\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "memory = CentralMemory.get_memory_instance()\n",
    "# need to write it manually to memory as score table has a foreign key constraint\n",
    "memory.add_message_to_memory(request=response)\n",
    "\n",
    "# Run the request\n",
    "scores = await azure_content_filter.score_async(response)  # type: ignore\n",
    "assert scores[0].get_value() > 0  # azure_severity should be value 2 based on the documentation\n",
    "\n",
    "for score in scores:\n",
    "    # score_metadata contains azure_severity original value\n",
    "    print(f\"{score} {score.score_metadata}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
