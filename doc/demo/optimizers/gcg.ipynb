{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient, command\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Environment, BuildContext, JobResourceConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../../configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyrit.common import default_values\n",
    "\n",
    "default_values.load_default_env()\n",
    "\n",
    "# Enter details of your AML workspace\n",
    "subscription_id = os.environ.get('AZURE_SUBSCRIPTION_ID')\n",
    "resource_group = os.environ.get('AZURE_RESOURCE_GROUP')\n",
    "workspace = os.environ.get('AZURE_ML_WORKSPACE_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configure the Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading src (0.0 MBs): 100%|##########| 1066/1066 [00:00<00:00, 2299.45it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Environment({'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'pyrit-gcg', 'description': 'PyRIT environment created from a Docker context.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': True, 'id': '/subscriptions/6d13156d-cc60-485a-9e9e-54857689f99b/resourceGroups/romanlutz-southcentralus/providers/Microsoft.MachineLearningServices/workspaces/romanlutz-southcentralus/environments/pyrit-gcg/versions/1', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\bbullwinkel\\\\OneDrive - Microsoft\\\\Documents\\\\AIRT\\\\PyRIT\\\\doc\\\\demo\\\\optimizers', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000002B7077A4D10>, 'serialize': <msrest.serialization.Serializer object at 0x000002B7078EEE50>, 'version': '1', 'latest_version': None, 'conda_file': None, 'image': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x000002B703131450>, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_docker_context = Environment(\n",
    "    build=BuildContext(path=\"src\"),\n",
    "    name=\"pyrit-gcg\",\n",
    "    description=\"PyRIT environment created from a Docker context.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = command(\n",
    "    code=\"./../../..\",  # local path where the code is stored\n",
    "    command=\"cd pyrit/optimizers/experiments && python run.py --model_name ${{inputs.model_name}} --setup ${{inputs.setup}} --n_train_data ${{inputs.n_train_data}} --n_test_data ${{inputs.n_test_data}} --n_steps ${{inputs.n_steps}} --batch_size ${{inputs.batch_size}}\",\n",
    "    inputs={\n",
    "        \"model_name\": \"llama_2\", # \"all_models\",\n",
    "        \"setup\": \"multiple\",\n",
    "        \"n_train_data\": 25,\n",
    "        \"n_test_data\": 0,\n",
    "        \"n_steps\": 500,\n",
    "        \"batch_size\": 512,\n",
    "    },\n",
    "    environment=f\"{env_docker_context.name}:{env_docker_context.version}\",\n",
    "    environment_variables={\"HF_TOKEN\": os.environ[\"HF_TOKEN\"]},\n",
    "    display_name=\"suffix_generation\",\n",
    "    description=\"Generate a suffix for attacking LLMs.\",\n",
    "    resources = JobResourceConfiguration(\n",
    "        instance_type=\"Standard_NC6s_v3\", #\"Standard_ND96amsr_A100_v4\",\n",
    "        instance_count=1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Command \n",
    "Using the `MLClient` created earlier, we will now run this Command in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading PyRIT (52.06 MBs): 100%|##########| 52057259/52057259 [00:21<00:00, 2396868.89it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# submit the command\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Run Command to train a neural network with PyTorch on Iris dataset"
  },
  "kernelspec": {
   "display_name": "pyrit-python311-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
