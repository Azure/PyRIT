datasets:
  - ./pyrit/datasets/seed_prompts/illegal.prompt
scenarios:
  - type: "RedTeamingAttack"
  # - type: "CrescendoAttack"
  # - type: "TreeOfAttacksWithPruningAttack"
  #   depth: 2
objective_target:
  type: "OpenAIChatTarget" # "AzureMLChatTarget" | "HuggingFaceEndpointTarget" | ...
  # endpoint_env_variable: # in case one wants to use multiple you need to specify the env vars - not yet supported
  # api_key_env_variable:
  # any arg for targets can be listed here:
  # deployment_name_env_variable:
  # headers:
# converters:
#   - type: "Base64Converter"
#   - type: "LeetspeakConverter"
attack_adversarial_config:
  type: "OpenAIChatTarget"
scoring:
  # scoring_target is optional. If a target is required but not provided, the adversarial_chat will be used for scoring
  # scoring_target:
  #   type: "OpenAIChatTarget"
  objective_scorer:
    type: "SelfAskTrueFalseScorer"
    true_false_question_path: pyrit/score/config/true_false_question/task_achieved.yaml
database:
  type: "SQLite"
  memory_labels:
    operator: roakey
    operation: op_trash_panda
execution_settings:
  type: local # or "azureml" - not yet supported
  # parallel_nodes: 4 # how many scenarios to execute in parallel - not yet supported
