datasets:
  - ./pyrit/datasets/seed_prompts/illegal.prompt
scenarios:
  - type: "RedTeamingOrchestrator"
  # - type: "CrescendoOrchestrator"
  # - type: "TreeOfAttacksWithPruningOrchestrator"
  #   depth: 2
objective_target:
  type: "OpenAIChatTarget" # "AzureMLChatTarget" | "HuggingFaceEndpointTarget" | ...
  # endpoint_env_variable: # in case one wants to use multiple you need to specify the env vars - not yet supported
  # api_key_env_variable:
  # any arg for targets can be listed here:
  # deployment_name_env_variable:
  # headers:
# converters:
#   - type: "Base64Converter"
#   - type: "LeetspeakConverter"
adversarial_chat:
  type: "OpenAIChatTarget"
  is_azure_target: true
scoring:
  # scoring_target is optional. If a target is required but not provided, the adversarial_chat will be used for scoring
  # scoring_target:
  #   type: "OpenAIChatTarget"
  objective_scorer:
    type: "SelfAskRefusalScorer"
database:
  type: "DuckDB"
  memory_labels:
    operator: roakey
    operation: op_trash_panda
execution_settings:
  type: local # or "azureml"
  # parallel_nodes: 4 # how many scenarios to execute in parallel
